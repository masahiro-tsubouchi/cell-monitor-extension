#!/usr/bin/env python3
"""
JupyterLab Cell Monitor Extension - ç’°å¢ƒå¤‰æ•°å¯¾å¿œè² è·ãƒ†ã‚¹ãƒˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿
.envãƒ•ã‚¡ã‚¤ãƒ«ã®è¨­å®šã«åŸºã¥ã„ã¦å—è¬›ç”Ÿæ•°ã‚„ãƒ†ã‚¹ãƒˆæ¡ä»¶ã‚’å‹•çš„ã«å¤‰æ›´å¯èƒ½

ãƒ†ã‚¹ãƒˆæ§‹æˆï¼ˆ.envè¨­å®šå¯èƒ½ï¼‰:
- å—è¬›ç”Ÿæ•°: LOAD_TEST_STUDENT_COUNT (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 100å)
- ãƒãƒ¼ãƒ ã‚µã‚¤ã‚º: LOAD_TEST_TEAM_SIZE (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5å)
- å®Ÿè¡Œæ™‚é–“: LOAD_TEST_DURATION_MINUTES (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10åˆ†)
- è¬›å¸«æ•°: LOAD_TEST_INSTRUCTOR_COUNT (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5å)
"""

import asyncio
import json
import time
import random
import aiohttp
import logging
import psutil
import os
from datetime import datetime
from typing import List, Dict, Optional
from dataclasses import dataclass, field
from pathlib import Path

# .envãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
from dotenv import load_dotenv
load_dotenv()

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’å–å¾—
class LoadTestConfig:
    """è² è·ãƒ†ã‚¹ãƒˆè¨­å®šã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.student_count = int(os.getenv('LOAD_TEST_STUDENT_COUNT', '100'))
        self.team_size = int(os.getenv('LOAD_TEST_TEAM_SIZE', '5'))
        self.duration_minutes = int(os.getenv('LOAD_TEST_DURATION_MINUTES', '10'))
        self.instructor_count = int(os.getenv('LOAD_TEST_INSTRUCTOR_COUNT', '5'))
        self.cell_interval_min = int(os.getenv('LOAD_TEST_CELL_INTERVAL_MIN', '12'))
        self.cell_interval_max = int(os.getenv('LOAD_TEST_CELL_INTERVAL_MAX', '18'))
        self.help_interval_min = int(os.getenv('LOAD_TEST_HELP_INTERVAL_MIN', '90'))
        self.help_interval_max = int(os.getenv('LOAD_TEST_HELP_INTERVAL_MAX', '150'))
        self.batch_size = int(os.getenv('LOAD_TEST_BATCH_SIZE', '20'))
        self.gradual_mode = os.getenv('LOAD_TEST_GRADUAL_MODE', 'true').lower() == 'true'
        
        # è‡ªå‹•è¨ˆç®—å€¤
        self.team_count = max(1, self.student_count // self.team_size)
        self.expected_events_per_second = self.student_count * (60 / self.cell_interval_min) 
        
    def log_config(self):
        """è¨­å®šå†…å®¹ã‚’ãƒ­ã‚°å‡ºåŠ›"""
        logger.info(f"ğŸ”§ è² è·ãƒ†ã‚¹ãƒˆè¨­å®š (.env):")
        logger.info(f"   å—è¬›ç”Ÿæ•°: {self.student_count}å")
        logger.info(f"   ãƒãƒ¼ãƒ æ•°: {self.team_count}ãƒãƒ¼ãƒ  (ã‚µã‚¤ã‚º: {self.team_size}å)")
        logger.info(f"   å®Ÿè¡Œæ™‚é–“: {self.duration_minutes}åˆ†")
        logger.info(f"   è¬›å¸«æ•°: {self.instructor_count}å")
        logger.info(f"   ã‚»ãƒ«é–“éš”: {self.cell_interval_min}-{self.cell_interval_max}ç§’")
        logger.info(f"   ãƒ˜ãƒ«ãƒ—é–“éš”: {self.help_interval_min}-{self.help_interval_max}ç§’")
        logger.info(f"   æ®µéšçš„è² è·: {'æœ‰åŠ¹' if self.gradual_mode else 'ç„¡åŠ¹'}")
        logger.info(f"   äºˆæƒ³è² è·: ~{self.expected_events_per_second:.0f}ã‚¤ãƒ™ãƒ³ãƒˆ/ç§’")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®šã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
config = LoadTestConfig()

@dataclass
class Student:
    """æ‹¡å¼µå—è¬›ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    id: int
    email: str
    name: str
    team: str
    team_id: int
    notebook_id: str = None
    session_id: str = None
    help_requested: bool = False
    cell_count: int = 0
    error_count: int = 0
    last_activity: float = 0
    total_response_time: float = 0
    response_count: int = 0

@dataclass
class PerformanceMetrics:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ˆæ¸¬ãƒ‡ãƒ¼ã‚¿"""
    start_time: float = field(default_factory=time.time)
    events_sent: int = 0
    events_successful: int = 0
    events_failed: int = 0
    help_requests: int = 0
    avg_response_time: float = 0
    max_response_time: float = 0
    min_response_time: float = float('inf')
    system_metrics: Dict = field(default_factory=dict)
    redis_metrics: Dict = field(default_factory=dict)
    error_details: List = field(default_factory=list)

class EnhancedLoadTestSimulator:
    """ç’°å¢ƒå¤‰æ•°å¯¾å¿œæ‹¡å¼µè² è·ãƒ†ã‚¹ãƒˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿"""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.api_url = f"{base_url}/api/v1"
        self.students: List[Student] = []
        self.instructors: List[Dict] = []
        self.session = None
        self.performance = PerformanceMetrics()
        self.monitoring_data = {
            "timeline": [],
            "system_resources": [],
            "redis_connections": [],
            "response_times": []
        }
        
    def create_students(self) -> List[Student]:
        """ç’°å¢ƒå¤‰æ•°ã«åŸºã¥ã„ã¦å—è¬›ç”Ÿã‚’ä½œæˆ"""
        # ãƒãƒ¼ãƒ åç”Ÿæˆï¼ˆA, B, C... ã¾ãŸã¯ãƒãƒ¼ãƒ 1, ãƒãƒ¼ãƒ 2...ï¼‰
        if config.team_count <= 26:
            teams = [f"ãƒãƒ¼ãƒ {chr(65+i)}" for i in range(config.team_count)]  # ãƒãƒ¼ãƒ Aï½Z
        else:
            teams = [f"ãƒãƒ¼ãƒ {i+1:02d}" for i in range(config.team_count)]  # ãƒãƒ¼ãƒ 01ï½
        
        students = []
        
        for i in range(1, config.student_count + 1):
            team_index = (i - 1) // config.team_size
            # ãƒãƒ¼ãƒ æ•°ã‚’è¶…ãˆãŸå ´åˆã¯æœ€å¾Œã®ãƒãƒ¼ãƒ ã«è¿½åŠ 
            team_index = min(team_index, len(teams) - 1)
            
            student = Student(
                id=i,
                email=f"student{i:03d}@university.edu",
                name=f"å­¦ç”Ÿ{i:03d}",
                team=teams[team_index],
                team_id=team_index + 1,
                notebook_id=f"lecture_notebook_{i:03d}.ipynb",
                session_id=f"session_{i:03d}_{int(time.time())}"
            )
            students.append(student)
            
        self.students = students
        logger.info(f"âœ… å—è¬›ç”Ÿ{len(students)}åã‚’{len(teams)}ãƒãƒ¼ãƒ ã«ä½œæˆ")
        
        # ãƒãƒ¼ãƒ æ§‹æˆè¡¨ç¤ºï¼ˆæœ€åˆã®5ãƒãƒ¼ãƒ ã®ã¿ï¼‰
        display_teams = min(5, len(teams))
        for i, team in enumerate(teams[:display_teams]):
            team_members = [s.name for s in students if s.team == team]
            logger.info(f"ğŸ“‹ {team}: {', '.join(team_members)}")
        if len(teams) > display_teams:
            logger.info(f"   ... ä»–{len(teams)-display_teams}ãƒãƒ¼ãƒ ")
            
        return students
    
    def create_instructors(self) -> List[Dict]:
        """ç’°å¢ƒå¤‰æ•°ã«åŸºã¥ã„ã¦è¬›å¸«ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆ"""
        instructors = []
        for i in range(1, config.instructor_count + 1):
            instructor = {
                "id": i,
                "email": f"instructor{i:02d}@university.edu", 
                "name": f"è¬›å¸«{i:02d}",
                "dashboard_id": f"dashboard_{i:02d}_{int(time.time())}"
            }
            instructors.append(instructor)
            
        self.instructors = instructors
        logger.info(f"âœ… è¬›å¸«{len(instructors)}åã®ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆ")
        return instructors
    
    async def send_enhanced_cell_event(self, student: Student, success: bool = True) -> float:
        """JupyterLabå®Ÿä»•æ§˜å¯¾å¿œã‚»ãƒ«å®Ÿè¡Œã‚¤ãƒ™ãƒ³ãƒˆé€ä¿¡"""
        cell_id = f"cell_{student.cell_count + 1:03d}"
        execution_time = random.uniform(0.2, 4.0)  # ã‚ˆã‚Šç¾å®Ÿçš„ãªå®Ÿè¡Œæ™‚é–“
        
        # JupyterLab Extension ã®æ­£å¼ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—
        # æˆåŠŸ/å¤±æ•—é–¢ä¿‚ãªã 'cell_executed' ã®ã¿ï¼ˆhasErrorã§åˆ¤å®šï¼‰
        event_data = {
            "eventId": f"cell_{student.id}_{int(time.time())}_{student.cell_count}",  # JupyterLabä»•æ§˜
            "eventType": "cell_executed",  # JupyterLabä»•æ§˜ã«çµ±ä¸€
            "eventTime": datetime.now().isoformat(),
            "emailAddress": student.email,
            "userName": student.name,
            "teamName": student.team,
            "teamId": student.team_id,
            "notebookPath": student.notebook_id,
            "sessionId": student.session_id,
            "cellId": cell_id,
            "cellIndex": student.cell_count,  # JupyterLabä»•æ§˜
            "cellType": "code",  # JupyterLabã§ã¯ä¸»ã«code
            "code": self._generate_realistic_code(success),
            "executionCount": student.cell_count + 1,
            "executionDurationMs": int(execution_time * 1000),
            "hasError": not success,  # JupyterLabä»•æ§˜ã®ã‚¨ãƒ©ãƒ¼åˆ¤å®š
            "errorMessage": self._generate_realistic_output(success) if not success else None,
            "result": self._generate_realistic_output(success),
            "metadata": {
                "source": "enhanced_100_student_simulator",
                "test_phase": "production_readiness_test",
                "cpu_load": psutil.cpu_percent(),
                "memory_usage": psutil.virtual_memory().percent
            }
        }
        
        start_time = time.time()
        try:
            async with self.session.post(
                f"{self.api_url}/events",
                json=[event_data],
                timeout=aiohttp.ClientTimeout(total=15)
            ) as response:
                response_time = time.time() - start_time
                
                if response.status in [200, 202]:
                    student.cell_count += 1
                    student.total_response_time += response_time
                    student.response_count += 1
                    student.last_activity = time.time()
                    
                    if not success:
                        student.error_count += 1
                    
                    self.performance.events_sent += 1
                    self.performance.events_successful += 1
                    self._update_performance_metrics(response_time)
                    
                    logger.debug(f"ğŸ“¤ {student.name}: ã‚»ãƒ«å®Ÿè¡ŒæˆåŠŸ (HTTP {response.status}, {response_time:.3f}s)")
                else:
                    error_text = await response.text()
                    self.performance.events_failed += 1
                    self.performance.error_details.append({
                        "student": student.name,
                        "status": response.status,
                        "error": error_text[:200],
                        "timestamp": datetime.now().isoformat()
                    })
                    logger.error(f"âŒ {student.name}: ã‚»ãƒ«å®Ÿè¡Œå¤±æ•— (HTTP {response.status})")
                    
                return response_time
                
        except Exception as e:
            response_time = time.time() - start_time
            self.performance.events_failed += 1
            self.performance.error_details.append({
                "student": student.name,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            })
            logger.error(f"âŒ {student.name}: ã‚»ãƒ«å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return response_time
    
    async def send_batch_events(self, students: List[Student], batch_size: int = 20) -> Dict:
        """ãƒãƒƒãƒã‚¤ãƒ™ãƒ³ãƒˆé€ä¿¡ï¼ˆã‚·ã‚¹ãƒ†ãƒ è² è·è»½æ¸›ï¼‰"""
        batch_events = []
        
        for student in students[:batch_size]:
            success = (student.cell_count + 1) % 3 != 0
            cell_id = f"cell_{student.cell_count + 1:03d}"
            
            event_data = {
                "eventId": f"batch_{student.id}_{int(time.time())}_{student.cell_count}",  # JupyterLabä»•æ§˜
                "eventType": "cell_executed",  # JupyterLabä»•æ§˜çµ±ä¸€
                "eventTime": datetime.now().isoformat(),
                "emailAddress": student.email,
                "userName": student.name,
                "teamName": student.team,
                "teamId": student.team_id,
                "notebookPath": student.notebook_id,
                "sessionId": student.session_id,
                "cellId": cell_id,
                "cellIndex": student.cell_count,  # JupyterLabä»•æ§˜
                "cellType": "code",
                "code": self._generate_realistic_code(success),
                "executionCount": student.cell_count + 1,
                "executionDurationMs": int(random.uniform(200, 4000)),
                "hasError": not success,  # JupyterLabä»•æ§˜
                "errorMessage": self._generate_realistic_output(success) if not success else None,
                "result": self._generate_realistic_output(success),
                "metadata": {
                    "source": "batch_simulator",
                    "batch_size": batch_size
                }
            }
            batch_events.append(event_data)
        
        start_time = time.time()
        try:
            async with self.session.post(
                f"{self.api_url}/events",
                json=batch_events,
                timeout=aiohttp.ClientTimeout(total=30)
            ) as response:
                response_time = time.time() - start_time
                
                if response.status in [200, 202]:
                    # ãƒãƒƒãƒæˆåŠŸæ™‚ã®çµ±è¨ˆæ›´æ–°
                    for student in students[:batch_size]:
                        student.cell_count += 1
                        if (student.cell_count) % 3 == 0:
                            student.error_count += 1
                    
                    self.performance.events_sent += len(batch_events)
                    self.performance.events_successful += len(batch_events)
                    logger.info(f"ğŸ“¦ ãƒãƒƒãƒé€ä¿¡æˆåŠŸ: {len(batch_events)}ã‚¤ãƒ™ãƒ³ãƒˆ ({response_time:.3f}s)")
                else:
                    error_text = await response.text()
                    self.performance.events_failed += len(batch_events)
                    logger.error(f"âŒ ãƒãƒƒãƒé€ä¿¡å¤±æ•—: HTTP {response.status}")
                
                return {
                    "success": response.status in [200, 202],
                    "response_time": response_time,
                    "batch_size": len(batch_events)
                }
                
        except Exception as e:
            self.performance.events_failed += len(batch_events)
            logger.error(f"âŒ ãƒãƒƒãƒé€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            return {"success": False, "error": str(e)}
    
    async def monitor_system_resources(self):
        """ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–ï¼ˆåˆ¥ã‚¿ã‚¹ã‚¯ï¼‰"""
        while True:
            try:
                # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—
                system_data = {
                    "timestamp": time.time(),
                    "cpu_percent": psutil.cpu_percent(interval=1),
                    "memory_percent": psutil.virtual_memory().percent,
                    "disk_io": psutil.disk_io_counters()._asdict() if psutil.disk_io_counters() else {},
                    "network_io": psutil.net_io_counters()._asdict()
                }
                
                # Redisæ¥ç¶šæƒ…å ±å–å¾—
                try:
                    async with self.session.get(
                        f"{self.api_url}/health/redis",
                        timeout=aiohttp.ClientTimeout(total=5)
                    ) as response:
                        if response.status == 200:
                            redis_data = await response.json()
                            system_data["redis_connections"] = redis_data.get("redis_info", {}).get("connected_clients", 0)
                            system_data["redis_pool_used"] = redis_data.get("pool_info", {}).get("created_connections", 0)
                except:
                    system_data["redis_connections"] = -1
                
                self.monitoring_data["system_resources"].append(system_data)
                
                # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒ80%è¶…ãˆãŸã‚‰è­¦å‘Š
                if system_data["memory_percent"] > 80:
                    logger.warning(f"ğŸš¨ é«˜ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {system_data['memory_percent']:.1f}%")
                
                await asyncio.sleep(5)  # 5ç§’é–“éš”ã§ç›£è¦–
                
            except Exception as e:
                logger.error(f"ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")
                await asyncio.sleep(10)
    
    async def simulate_enhanced_student_activity(self, student: Student, duration_minutes: int = None):
        """æ‹¡å¼µå—è¬›ç”Ÿæ´»å‹•ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        if duration_minutes is None:
            duration_minutes = config.duration_minutes
            
        end_time = time.time() + (duration_minutes * 60)
        
        # JupyterLabå®Ÿä»•æ§˜: å­¦ç¿’é–‹å§‹æ™‚ã«ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯é–‹å°ã‚¤ãƒ™ãƒ³ãƒˆ
        await self.send_notebook_event(student, "notebook_opened")
        
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰é–“éš”è¨­å®š
        base_cell_interval = random.uniform(config.cell_interval_min, config.cell_interval_max)
        base_help_interval = random.uniform(config.help_interval_min, config.help_interval_max)
        
        last_cell_time = 0
        last_help_time = 0
        last_save_time = 0
        save_interval = random.uniform(120, 300)  # 2-5åˆ†é–“éš”ã§ä¿å­˜
        burst_mode = False
        burst_end_time = 0
        
        while time.time() < end_time:
            current_time = time.time()
            
            # ãƒ©ãƒ³ãƒ€ãƒ ã«ãƒãƒ¼ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼ˆé›†ä¸­ä½œæ¥­ï¼‰
            if not burst_mode and random.random() < 0.05:  # 5%ã®ç¢ºç‡
                burst_mode = True
                burst_end_time = current_time + random.uniform(30, 120)
                logger.debug(f"ğŸ”¥ {student.name}: ãƒãƒ¼ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰é–‹å§‹")
            
            if burst_mode and current_time > burst_end_time:
                burst_mode = False
                logger.debug(f"ğŸ˜Œ {student.name}: ãƒãƒ¼ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰çµ‚äº†")
            
            # ã‚»ãƒ«å®Ÿè¡Œé–“éš”ï¼ˆãƒãƒ¼ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰æ™‚ã¯çŸ­ç¸®ï¼‰
            cell_interval = base_cell_interval * (0.3 if burst_mode else 1.0)
            
            # ã‚»ãƒ«å®Ÿè¡Œ
            if current_time - last_cell_time >= cell_interval:
                # æ™‚é–“å¸¯ã«ã‚ˆã‚‹æˆåŠŸç‡å¤‰å‹•
                hour = datetime.now().hour
                if 14 <= hour <= 16:  # åˆå¾Œã®é›†ä¸­æ™‚é–“
                    success_rate = 0.8
                else:
                    success_rate = 0.67  # é€šå¸¸æ™‚
                
                success = random.random() < success_rate
                await self.send_enhanced_cell_event(student, success)
                last_cell_time = current_time
                
            # ãƒ˜ãƒ«ãƒ—è¦è«‹
            if current_time - last_help_time >= base_help_interval:
                if not student.help_requested and random.random() < 0.7:
                    await self.send_help_request(student)
                elif student.help_requested:
                    await self.send_help_stop(student)
                last_help_time = current_time
            
            # JupyterLabå®Ÿä»•æ§˜: å®šæœŸçš„ãªãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ä¿å­˜
            if current_time - last_save_time >= save_interval:
                await self.send_notebook_event(student, "notebook_saved")
                last_save_time = current_time
                save_interval = random.uniform(120, 300)  # æ¬¡å›ä¿å­˜é–“éš”ã‚’ãƒ©ãƒ³ãƒ€ãƒ åŒ–
                
            # å‹•çš„å¾…æ©Ÿæ™‚é–“
            await asyncio.sleep(random.uniform(0.5, 2.0))
        
        # æ´»å‹•çµ‚äº†å‡¦ç†
        if student.help_requested:
            await self.send_help_stop(student)
            
        # JupyterLabå®Ÿä»•æ§˜: å­¦ç¿’çµ‚äº†æ™‚ã«ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯çµ‚äº†ã‚¤ãƒ™ãƒ³ãƒˆ
        await self.send_notebook_event(student, "notebook_closed")
            
        avg_response = student.total_response_time / max(student.response_count, 1)
        success_rate = ((student.cell_count - student.error_count) / max(student.cell_count, 1)) * 100
        logger.info(f"ğŸ {student.name}: æ´»å‹•çµ‚äº† (ã‚»ãƒ«: {student.cell_count}, ã‚¨ãƒ©ãƒ¼: {student.error_count}, "
                   f"æˆåŠŸç‡: {success_rate:.1f}%, å¹³å‡å¿œç­”: {avg_response:.3f}s)")
    
    async def send_help_request(self, student: Student) -> bool:
        """JupyterLabå®Ÿä»•æ§˜ãƒ˜ãƒ«ãƒ—è¦è«‹é€ä¿¡"""
        event_data = {
            "eventId": f"help_{student.id}_{int(time.time())}",  # JupyterLabä»•æ§˜
            "eventType": "help",
            "eventTime": datetime.now().isoformat(),
            "emailAddress": student.email,
            "userName": student.name,
            "teamName": student.team,
            "sessionId": student.session_id,
            "notebookPath": student.notebook_id,
            # JupyterLabä»•æ§˜ã§ã¯ result ã¯ä½¿ã‚ãªã„
            "metadata": {
                "source": "jupyterlab_extension_simulator",
                "help_reason": random.choice([
                    "ã‚¨ãƒ©ãƒ¼ãŒè§£æ±ºã§ãã¾ã›ã‚“",
                    "å®Ÿè¡ŒãŒé…ã™ãã¾ã™", 
                    "æœŸå¾…ã—ãŸçµæœã«ãªã‚Šã¾ã›ã‚“",
                    "ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã™"
                ])
            }
        }
        
        try:
            async with self.session.post(
                f"{self.api_url}/events",
                json=[event_data],
                timeout=aiohttp.ClientTimeout(total=5)
            ) as response:
                if response.status in [200, 202]:
                    student.help_requested = True
                    self.performance.help_requests += 1
                    logger.debug(f"ğŸ†˜ {student.name}: ãƒ˜ãƒ«ãƒ—è¦è«‹é€ä¿¡æˆåŠŸ")
                    return True
                else:
                    logger.error(f"âŒ {student.name}: ãƒ˜ãƒ«ãƒ—è¦è«‹å¤±æ•— (HTTP {response.status})")
                    return False
        except Exception as e:
            logger.error(f"âŒ {student.name}: ãƒ˜ãƒ«ãƒ—è¦è«‹ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    async def send_help_stop(self, student: Student) -> bool:
        """JupyterLabå®Ÿä»•æ§˜ãƒ˜ãƒ«ãƒ—è¦è«‹åœæ­¢é€ä¿¡"""
        if not student.help_requested:
            return True
            
        event_data = {
            "eventId": f"help_stop_{student.id}_{int(time.time())}",  # JupyterLabä»•æ§˜
            "eventType": "help_stop",
            "eventTime": datetime.now().isoformat(),
            "emailAddress": student.email,
            "userName": student.name,
            "teamName": student.team,
            "sessionId": student.session_id,
            "notebookPath": student.notebook_id,
            # JupyterLabä»•æ§˜ã§ã¯ result ã¯ä½¿ã‚ãªã„
            "metadata": {
                "source": "jupyterlab_extension_simulator",
                "help_resolved": True
            }
        }
        
        try:
            async with self.session.post(
                f"{self.api_url}/events",
                json=[event_data],
                timeout=aiohttp.ClientTimeout(total=5)
            ) as response:
                if response.status in [200, 202]:
                    student.help_requested = False
                    logger.debug(f"âœ… {student.name}: ãƒ˜ãƒ«ãƒ—è¦è«‹åœæ­¢æˆåŠŸ")
                    return True
                else:
                    logger.error(f"âŒ {student.name}: ãƒ˜ãƒ«ãƒ—è¦è«‹åœæ­¢å¤±æ•— (HTTP {response.status})")
                    return False
        except Exception as e:
            logger.error(f"âŒ {student.name}: ãƒ˜ãƒ«ãƒ—è¦è«‹åœæ­¢ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    async def send_notebook_event(self, student: Student, event_type: str) -> bool:
        """JupyterLabå®Ÿä»•æ§˜ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆé€ä¿¡"""
        event_data = {
            "eventId": f"notebook_{event_type}_{student.id}_{int(time.time())}",
            "eventType": event_type,  # notebook_opened, notebook_saved, notebook_closed
            "eventTime": datetime.now().isoformat(),
            "emailAddress": student.email,
            "userName": student.name,
            "teamName": student.team,
            "sessionId": student.session_id,
            "notebookPath": student.notebook_id,
            "metadata": {
                "source": "jupyterlab_extension_simulator"
            }
        }
        
        try:
            async with self.session.post(
                f"{self.api_url}/events",
                json=[event_data],
                timeout=aiohttp.ClientTimeout(total=5)
            ) as response:
                if response.status in [200, 202]:
                    logger.debug(f"ğŸ““ {student.name}: ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯{event_type}é€ä¿¡æˆåŠŸ")
                    return True
                else:
                    logger.error(f"âŒ {student.name}: ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯{event_type}é€ä¿¡å¤±æ•— (HTTP {response.status})")
                    return False
        except Exception as e:
            logger.error(f"âŒ {student.name}: ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯{event_type}é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    async def run_enhanced_load_test(self, duration_minutes: int = None):
        """ç’°å¢ƒå¤‰æ•°å¯¾å¿œæ‹¡å¼µè² è·ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        if duration_minutes is None:
            duration_minutes = config.duration_minutes
            
        self.performance.start_time = time.time()
        
        # è¨­å®šå†…å®¹ã‚’ãƒ­ã‚°å‡ºåŠ›
        config.log_config()
        logger.info(f"ğŸš€ æ‹¡å¼µè² è·ãƒ†ã‚¹ãƒˆé–‹å§‹ (å®Ÿè¡Œæ™‚é–“: {duration_minutes}åˆ†)")
        
        # HTTPã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆï¼ˆå—è¬›ç”Ÿæ•°ã«å¿œã˜ãŸæœ€é©åŒ–è¨­å®šï¼‰
        connector = aiohttp.TCPConnector(
            limit=config.student_count + config.instructor_count + 50,  # å‹•çš„ + ãƒãƒƒãƒ•ã‚¡
            limit_per_host=max(100, config.student_count + 20),
            ttl_dns_cache=300,
            use_dns_cache=True,
            keepalive_timeout=30
        )
        self.session = aiohttp.ClientSession(connector=connector)
        
        try:
            # å—è¬›ç”Ÿãƒ»è¬›å¸«ä½œæˆ
            self.create_students()
            self.create_instructors()
            
            # ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–é–‹å§‹
            monitor_task = asyncio.create_task(self.monitor_system_resources())
            
            if config.gradual_mode and config.student_count >= 50:
                # æ®µéšçš„è² è·å¢—åŠ ï¼ˆæœ¬ç•ªç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼‰
                logger.info("ğŸ“ˆ æ®µéšçš„è² è·å¢—åŠ ãƒ¢ãƒ¼ãƒ‰")
                
                # Phase 1: 25%ã§ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
                phase1_count = max(10, config.student_count // 4)
                phase1_duration = max(2, duration_minutes // 3)
                logger.info(f"ğŸ”¥ Phase 1: {phase1_count}åã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ— ({phase1_duration}åˆ†)")
                phase1_tasks = [
                    self.simulate_enhanced_student_activity(student, phase1_duration)
                    for student in self.students[:phase1_count]
                ]
                await asyncio.gather(*phase1_tasks)
                
                # Phase 2: 50%ã§ä¸­è² è·
                phase2_count = max(phase1_count, config.student_count // 2)
                phase2_duration = max(2, duration_minutes // 3)
                logger.info(f"ğŸ”¥ Phase 2: {phase2_count}åä¸­è² è·ãƒ†ã‚¹ãƒˆ ({phase2_duration}åˆ†)")
                phase2_tasks = [
                    self.simulate_enhanced_student_activity(student, phase2_duration)
                    for student in self.students[:phase2_count]
                ]
                await asyncio.gather(*phase2_tasks)
                
                # Phase 3: 100%ãƒ•ãƒ«è² è·
                phase3_duration = duration_minutes - phase1_duration - phase2_duration
                logger.info(f"ğŸ”¥ Phase 3: {config.student_count}åãƒ•ãƒ«è² è·ãƒ†ã‚¹ãƒˆ ({phase3_duration}åˆ†)")
                phase3_tasks = [
                    self.simulate_enhanced_student_activity(student, phase3_duration)
                    for student in self.students
                ]
                await asyncio.gather(*phase3_tasks)
            else:
                # ä¸€æ‹¬å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰
                logger.info(f"ğŸ”¥ ä¸€æ‹¬å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: {config.student_count}å ({duration_minutes}åˆ†)")
                all_tasks = [
                    self.simulate_enhanced_student_activity(student, duration_minutes)
                    for student in self.students
                ]
                await asyncio.gather(*all_tasks)
            
            # ç›£è¦–åœæ­¢
            monitor_task.cancel()
            
            # æœ€çµ‚çµæœé›†è¨ˆ
            self._compile_enhanced_results()
            
        finally:
            await self.session.close()
            
        logger.info(f"âœ… {config.student_count}åæ‹¡å¼µè² è·ãƒ†ã‚¹ãƒˆå®Œäº†")
        return self._generate_comprehensive_report()
    
    def _generate_realistic_code(self, success: bool) -> str:
        """ç¾å®Ÿçš„ãªã‚³ãƒ¼ãƒ‰ç”Ÿæˆ"""
        if success:
            codes = [
                "import pandas as pd\ndf = pd.read_csv('data.csv')\nprint(df.head())",
                "import numpy as np\ndata = np.random.randn(1000)\nresult = np.mean(data)",
                "from sklearn.model_selection import train_test_split\nX_train, X_test = train_test_split(X, test_size=0.2)",
                "import matplotlib.pyplot as plt\nplt.plot([1,2,3,4])\nplt.show()",
                "for i in range(100):\n    if i % 10 == 0:\n        print(f'Progress: {i}%')"
            ]
        else:
            codes = [
                "df = pd.read_csv('missing_file.csv')",  # FileNotFoundError
                "result = undefined_variable + 10",      # NameError
                "data[999999]",                          # IndexError
                "import non_existent_package",           # ImportError
                "1 / 0"                                  # ZeroDivisionError
            ]
        return random.choice(codes)
    
    def _generate_realistic_output(self, success: bool) -> str:
        """ç¾å®Ÿçš„ãªå‡ºåŠ›ç”Ÿæˆ"""
        if success:
            return "å®Ÿè¡ŒæˆåŠŸ: ãƒ‡ãƒ¼ã‚¿å‡¦ç†å®Œäº†"
        else:
            errors = [
                "FileNotFoundError: 'missing_file.csv' not found",
                "NameError: name 'undefined_variable' is not defined",
                "IndexError: list index out of range",
                "ImportError: No module named 'non_existent_package'",
                "ZeroDivisionError: division by zero"
            ]
            return random.choice(errors)
    
    def _update_performance_metrics(self, response_time: float):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™æ›´æ–°"""
        self.performance.max_response_time = max(self.performance.max_response_time, response_time)
        self.performance.min_response_time = min(self.performance.min_response_time, response_time)
        
        # ç§»å‹•å¹³å‡è¨ˆç®—
        total_successful = self.performance.events_successful
        current_avg = self.performance.avg_response_time
        self.performance.avg_response_time = (current_avg * (total_successful - 1) + response_time) / total_successful
        
        # å¿œç­”æ™‚é–“å±¥æ­´ä¿å­˜
        self.monitoring_data["response_times"].append({
            "timestamp": time.time(),
            "response_time": response_time
        })
    
    def _compile_enhanced_results(self):
        """æ‹¡å¼µçµæœã‚³ãƒ³ãƒ‘ã‚¤ãƒ«"""
        total_duration = time.time() - self.performance.start_time
        
        # å­¦ç”Ÿåˆ¥çµ±è¨ˆ
        student_stats = {}
        total_cells = 0
        total_errors = 0
        
        for student in self.students:
            student_stats[student.email] = {
                "name": student.name,
                "team": student.team,
                "cells_executed": student.cell_count,
                "errors_occurred": student.error_count,
                "avg_response_time": student.total_response_time / max(student.response_count, 1),
                "success_rate": ((student.cell_count - student.error_count) / max(student.cell_count, 1)) * 100
            }
            total_cells += student.cell_count
            total_errors += student.error_count
        
        # ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆ
        self.performance.system_metrics = {
            "total_duration_minutes": total_duration / 60,
            "events_per_second": self.performance.events_sent / total_duration,
            "success_rate": (self.performance.events_successful / max(self.performance.events_sent, 1)) * 100,
            "total_students": len(self.students),
            "total_teams": len(set(s.team for s in self.students)),
            "total_cells_executed": total_cells,
            "total_errors": total_errors,
            "student_stats": student_stats
        }
    
    def _generate_comprehensive_report(self) -> Dict:
        """åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        return {
            "test_info": {
                "start_time": datetime.fromtimestamp(self.performance.start_time).isoformat(),
                "duration_minutes": (time.time() - self.performance.start_time) / 60,
                "students": len(self.students),
                "teams": len(set(s.team for s in self.students)),
                "instructors": len(self.instructors)
            },
            "performance_metrics": {
                "events_sent": self.performance.events_sent,
                "events_successful": self.performance.events_successful,
                "events_failed": self.performance.events_failed,
                "success_rate": (self.performance.events_successful / max(self.performance.events_sent, 1)) * 100,
                "events_per_second": self.performance.system_metrics.get("events_per_second", 0),
                "avg_response_time": self.performance.avg_response_time,
                "max_response_time": self.performance.max_response_time,
                "min_response_time": self.performance.min_response_time if self.performance.min_response_time != float('inf') else 0,
                "help_requests": self.performance.help_requests
            },
            "system_metrics": self.performance.system_metrics,
            "monitoring_data": self.monitoring_data,
            "error_details": self.performance.error_details[:10]  # æœ€åˆã®10ä»¶ã®ã¿
        }
    
    def save_results(self, results: Dict, output_dir: str = "test_results"):
        """çµæœä¿å­˜"""
        Path(output_dir).mkdir(exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # JSONçµæœä¿å­˜
        json_file = Path(output_dir) / f"{config.student_count}_student_test_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2, default=str)
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report_file = Path(output_dir) / f"{config.student_count}_student_report_{timestamp}.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(self._generate_markdown_report(results))
        
        logger.info(f"ğŸ“Š çµæœä¿å­˜å®Œäº†: {json_file}, {report_file}")
        return str(json_file), str(report_file)
    
    def _generate_markdown_report(self, results: Dict) -> str:
        """Markdownãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        test_info = results["test_info"]
        perf = results["performance_metrics"]
        
        report = f"""# ğŸ§ª {config.student_count}åæ‹¡å¼µè² è·ãƒ†ã‚¹ãƒˆçµæœãƒ¬ãƒãƒ¼ãƒˆ

## ğŸ“Š ãƒ†ã‚¹ãƒˆæ¦‚è¦
- **é–‹å§‹æ™‚åˆ»**: {test_info["start_time"]}
- **å®Ÿè¡Œæ™‚é–“**: {test_info["duration_minutes"]:.1f}åˆ†
- **å—è¬›ç”Ÿæ•°**: {test_info["students"]}å
- **ãƒãƒ¼ãƒ æ•°**: {test_info["teams"]}ãƒãƒ¼ãƒ 
- **è¬›å¸«æ•°**: {test_info["instructors"]}å

## ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµæœ
- **é€ä¿¡ã‚¤ãƒ™ãƒ³ãƒˆæ•°**: {perf["events_sent"]:,}
- **æˆåŠŸã‚¤ãƒ™ãƒ³ãƒˆæ•°**: {perf["events_successful"]:,}
- **å¤±æ•—ã‚¤ãƒ™ãƒ³ãƒˆæ•°**: {perf["events_failed"]:,}
- **æˆåŠŸç‡**: {perf["success_rate"]:.2f}%
- **æ¯ç§’å‡¦ç†ã‚¤ãƒ™ãƒ³ãƒˆæ•°**: {perf["events_per_second"]:.1f}
- **ãƒ˜ãƒ«ãƒ—è¦è«‹æ•°**: {perf["help_requests"]:,}

## âš¡ å¿œç­”æ™‚é–“
- **å¹³å‡**: {perf["avg_response_time"]:.3f}ç§’
- **æœ€å¤§**: {perf["max_response_time"]:.3f}ç§’
- **æœ€å°**: {perf["min_response_time"]:.3f}ç§’

## ğŸ¯ ç›®æ¨™é”æˆåº¦
- **ç›®æ¨™å‡¦ç†èƒ½åŠ›**: 400ã‚¤ãƒ™ãƒ³ãƒˆ/ç§’ â†’ **å®Ÿæ¸¬**: {perf["events_per_second"]:.1f}ã‚¤ãƒ™ãƒ³ãƒˆ/ç§’
- **ç›®æ¨™æˆåŠŸç‡**: >99% â†’ **å®Ÿæ¸¬**: {perf["success_rate"]:.2f}%
- **ç›®æ¨™å¿œç­”æ™‚é–“**: <100ms â†’ **å®Ÿæ¸¬**: {perf["avg_response_time"]*1000:.0f}ms

## ğŸ“‹ çµè«–
{"âœ… **åˆæ ¼**: å…¨ç›®æ¨™ã‚’é”æˆ" if perf["success_rate"] > 99 and perf["avg_response_time"] < 0.1 and perf["events_per_second"] > 400 else "âš ï¸ **è¦æ”¹å–„**: ä¸€éƒ¨ç›®æ¨™æœªé”æˆ"}

## ğŸ’¡ æ¨å¥¨äº‹é …
1. Redisæ¥ç¶šãƒ—ãƒ¼ãƒ«ç›£è¦–ã®ç¶™ç¶š
2. å¿œç­”æ™‚é–“ã‚¹ãƒ‘ã‚¤ã‚¯å¯¾ç­–ã®æ¤œè¨
3. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®æ›´ãªã‚‹å¼·åŒ–
"""
        return report

# CLIå®Ÿè¡Œç”¨
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="JupyterLab Cell Monitor Extension ç’°å¢ƒå¤‰æ•°å¯¾å¿œæ‹¡å¼µè² è·ãƒ†ã‚¹ãƒˆ")
    parser.add_argument("--url", default="http://localhost:8000", help="FastAPI ã‚µãƒ¼ãƒãƒ¼URL")
    parser.add_argument("--duration", type=int, default=10, help="ãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ™‚é–“ï¼ˆåˆ†ï¼‰")
    parser.add_argument("--output-dir", default="test_results", help="çµæœå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--batch-mode", action="store_true", help="ãƒãƒƒãƒãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ")
    
    args = parser.parse_args()
    
    async def main():
        simulator = EnhancedLoadTestSimulator(args.url)
        
        if args.batch_mode:
            logger.info("ğŸš€ ãƒãƒƒãƒãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ")
            # ãƒãƒƒãƒãƒ†ã‚¹ãƒˆå®Ÿè£…ï¼ˆå°†æ¥æ‹¡å¼µï¼‰
            logger.warning("ãƒãƒƒãƒãƒ¢ãƒ¼ãƒ‰ã¯æœªå®Ÿè£…ã§ã™ã€‚é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã™ã€‚")
            results = await simulator.run_enhanced_load_test(args.duration)
        else:
            logger.info("ğŸš€ é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ")
            results = await simulator.run_enhanced_load_test(args.duration)
        
        # çµæœä¿å­˜
        json_file, report_file = simulator.save_results(results, args.output_dir)
        
        # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
        perf = results["performance_metrics"]
        print(f"\nğŸ¯ ãƒ†ã‚¹ãƒˆå®Œäº†!")
        print(f"ğŸ“¤ é€ä¿¡ã‚¤ãƒ™ãƒ³ãƒˆ: {perf['events_sent']:,}")
        print(f"âœ… æˆåŠŸç‡: {perf['success_rate']:.2f}%")
        print(f"âš¡ å‡¦ç†èƒ½åŠ›: {perf['events_per_second']:.1f}ã‚¤ãƒ™ãƒ³ãƒˆ/ç§’")
        print(f"ğŸ• å¹³å‡å¿œç­”æ™‚é–“: {perf['avg_response_time']*1000:.0f}ms")
        print(f"ğŸ“Š è©³ç´°çµæœ: {report_file}")
    
    asyncio.run(main())