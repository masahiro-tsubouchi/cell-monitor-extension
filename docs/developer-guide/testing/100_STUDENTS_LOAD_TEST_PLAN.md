# 100äººå—è¬›ç”Ÿãƒ‡ãƒ¼ã‚¿æ ¼ç´ãƒ†ã‚¹ãƒˆï¼šåŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆè¨ˆç”»æ›¸

> **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**: Cell Monitor Extension
> **ä½œæˆæ—¥**: 2025-01-19
> **åŸºç›¤**: 186å€‹ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹æˆåŠŸã®å®Ÿç¸¾
> **ç›®çš„**: 100äººåŒæ™‚å—è¬›ç’°å¢ƒã§ã®å®‰å®šã—ãŸãƒ‡ãƒ¼ã‚¿æ ¼ç´ãƒ»å‡¦ç†ã®å“è³ªä¿è¨¼

## ğŸ¯ ãƒ†ã‚¹ãƒˆæˆ¦ç•¥æ¦‚è¦

### **åŸºç›¤ã¨ãªã‚‹æˆåŠŸå®Ÿç¸¾**
- **Environment API**: 19å€‹å…¨æˆåŠŸ âœ…
- **Notebook Version API**: 22å€‹å…¨æˆåŠŸ âœ…
- **LMSçµ±åˆãƒ†ã‚¹ãƒˆ**: 9å€‹å…¨æˆåŠŸ âœ…
- **WebSocketçµ±åˆ**: 13å€‹å…¨æˆåŠŸ âœ…
- **è¬›å¸«ãƒ­ã‚°ã‚¤ãƒ³æ©Ÿèƒ½**: 123å€‹å…¨æˆåŠŸ âœ…
- **åˆè¨ˆ**: **186å€‹ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹å®Œå…¨æˆåŠŸ** ğŸ¯

### **ãƒ†ã‚¹ãƒˆç›®æ¨™**
1. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**: 100äººåŒæ™‚ã§1000ã‚¤ãƒ™ãƒ³ãƒˆ/ç§’ä»¥ä¸Š
2. **ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“**: 95ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ã§500msä»¥å†…
3. **ã‚¨ãƒ©ãƒ¼ç‡**: 0.1%ä»¥ä¸‹
4. **ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§**: PostgreSQL-InfluxDBé–“100%ä¸€è‡´
5. **ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡**: ãƒ¡ãƒ¢ãƒª4GBä»¥å†…ã€CPU80%ä»¥å†…

## ğŸ”§ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ä½¿ç”¨æ–¹æ³•

### **ç›£è¦–ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£æ¦‚è¦**

æ–°ãŸã«å®Ÿè£…ã•ã‚ŒãŸ `tests/utils/performance_monitor.py` ã¯ã€100äººå—è¬›ç”Ÿãƒ†ã‚¹ãƒˆå°‚ç”¨ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚æ—¢å­˜ã®186å€‹ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ´»ç”¨ã—ã€ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ»ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã‚’åŒ…æ‹¬çš„ã«ç›£è¦–ã—ã¾ã™ã€‚

### **åŸºæœ¬ä½¿ç”¨æ–¹æ³•**

#### 1. åŸºæœ¬çš„ãªç›£è¦–é–‹å§‹
```python
from tests.utils.performance_monitor import PerformanceMonitor

# åŸºæœ¬ç›£è¦–ã®é–‹å§‹
monitor = PerformanceMonitor()
await monitor.initialize_connections()

# ç›£è¦–é–‹å§‹ï¼ˆ1ç§’é–“éš”ï¼‰
await monitor.start_monitoring(interval_seconds=1.0)

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ...

# ç›£è¦–åœæ­¢
monitor.stop_monitoring()

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ç´„å–å¾—
summary = monitor.get_performance_summary()
print(f"ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹: {summary['health_status']}")
```

#### 2. è² è·ãƒ†ã‚¹ãƒˆå°‚ç”¨ç›£è¦–
```python
from tests.utils.performance_monitor import LoadTestMonitor

# è² è·ãƒ†ã‚¹ãƒˆç›£è¦–ï¼ˆé«˜é »åº¦0.5ç§’é–“éš”ï¼‰
monitor = LoadTestMonitor("100_students_phase_5", expected_load=100)
await monitor.initialize_connections()
await monitor.start_load_test_monitoring()

# 100äººå—è¬›ç”Ÿã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
# ...

# ç›£è¦–çµ‚äº†ã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
monitor.finish_load_test_monitoring()
report = monitor.generate_load_test_report()

# æˆåŠŸåŸºæº–ãƒã‚§ãƒƒã‚¯
success_criteria = report["success_criteria"]
assert success_criteria["cpu_under_80_percent"], "CPUä½¿ç”¨ç‡ãŒ80%ã‚’è¶…é"
assert success_criteria["response_time_under_500ms"], "ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ãŒ500msã‚’è¶…é"
```

#### 3. ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹çµ±åˆä¾‹
```python
@pytest.mark.asyncio
async def test_100_students_with_monitoring():
    """100äººå—è¬›ç”Ÿãƒ†ã‚¹ãƒˆï¼ˆç›£è¦–çµ±åˆç‰ˆï¼‰"""

    # ç›£è¦–é–‹å§‹
    monitor = LoadTestMonitor("100_students_full_test", expected_load=100)
    await monitor.initialize_connections()
    await monitor.start_load_test_monitoring()

    try:
        # 100äººåˆ†ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        from tests.utils.data_generator import StudentDataGenerator
        generator = StudentDataGenerator()

        # ãƒ•ã‚§ãƒ¼ã‚º1: 10äººï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰
        events_10 = generator.generate_classroom_session(num_students=10)
        await send_events_batch(events_10)

        # ãƒ•ã‚§ãƒ¼ã‚º2-5: æ®µéšçš„è² è·å¢—åŠ 
        for phase, num_students in [(2, 25), (3, 50), (4, 75), (5, 100)]:
            events = generator.generate_classroom_session(num_students=num_students)
            await send_events_batch(events)

            # å„ãƒ•ã‚§ãƒ¼ã‚ºã§ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
            current_metrics = await monitor.collect_current_metrics()
            health = monitor.analyze_system_health(current_metrics)
            assert health.overall_status != "critical", f"Phase {phase}: ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ãŒã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«"

    finally:
        # ç›£è¦–çµ‚äº†
        monitor.finish_load_test_monitoring()

        # è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = monitor.generate_load_test_report()

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’JSONã§ä¿å­˜
        monitor.export_metrics_to_json(f"test_results/100_students_metrics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")

        # æˆåŠŸåŸºæº–æ¤œè¨¼
        assert report["success_criteria"]["cpu_under_80_percent"]
        assert report["success_criteria"]["memory_under_4gb"]
        assert report["success_criteria"]["response_time_under_500ms"]
        assert report["success_criteria"]["error_rate_under_0_1_percent"]
```

### **ç›£è¦–ãƒ¡ãƒˆãƒªã‚¯ã‚¹è©³ç´°**

#### ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹
- **CPUä½¿ç”¨ç‡**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ã€è­¦å‘Š(70%)ãƒ»ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«(85%)ã—ãã„å€¤
- **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡**: ä½¿ç”¨ç‡ã¨MBå˜ä½ã§ã®ä½¿ç”¨é‡
- **ãƒ‡ã‚£ã‚¹ã‚¯I/O**: èª­ã¿æ›¸ãMB/ç§’
- **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯I/O**: é€å—ä¿¡MB/ç§’

#### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
- **Redisæ¥ç¶šæ•°**: ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ¥ç¶šæ•°
- **PostgreSQLæ¥ç¶šæ•°**: ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°
- **InfluxDB**: ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆæ•°ï¼ˆè¨­å®šæ™‚ï¼‰

#### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™
- **ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“**: API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®å¿œç­”æ™‚é–“ï¼ˆmsï¼‰
- **ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ**: ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†æ•°/ç§’
- **ã‚¨ãƒ©ãƒ¼ç‡**: å…¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«å¯¾ã™ã‚‹ã‚¨ãƒ©ãƒ¼ã®å‰²åˆ
- **WebSocketæ¥ç¶šæ•°**: ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªWebSocketæ¥ç¶šæ•°

### **ã‚¢ãƒ©ãƒ¼ãƒˆãƒ»ã—ãã„å€¤è¨­å®š**

```python
# ã‚«ã‚¹ã‚¿ãƒ ã—ãã„å€¤è¨­å®šä¾‹
monitor = PerformanceMonitor()
monitor.thresholds.update({
    "cpu_warning": 60.0,      # CPUè­¦å‘Šãƒ¬ãƒ™ãƒ«ã‚’60%ã«ä¸‹ã’ã‚‹
    "cpu_critical": 75.0,     # CPUå±é™ºãƒ¬ãƒ™ãƒ«ã‚’75%ã«ä¸‹ã’ã‚‹
    "memory_warning": 60.0,   # ãƒ¡ãƒ¢ãƒªè­¦å‘Šãƒ¬ãƒ™ãƒ«
    "response_time_warning": 800.0,  # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“è­¦å‘Šï¼ˆ800msï¼‰
    "error_rate_critical": 0.02,     # ã‚¨ãƒ©ãƒ¼ç‡å±é™ºãƒ¬ãƒ™ãƒ«ï¼ˆ2%ï¼‰
})
```

### **ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ã¨ãƒ‡ãƒãƒƒã‚°**

```python
# è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆä¾‹
report = monitor.generate_load_test_report()
print(json.dumps(report, indent=2, ensure_ascii=False))

# å‡ºåŠ›ä¾‹:
{
  "test_name": "100_students_phase_5",
  "expected_load": 100,
  "test_duration_seconds": 120.5,
  "performance_summary": {
    "latest_metrics": {...},
    "statistics": {
      "cpu": {"current": 45.2, "average": 38.7, "peak": 67.3},
      "memory": {"current": 52.1, "average": 48.9, "peak": 58.7}
    }
  },
  "success_criteria": {
    "cpu_under_80_percent": true,
    "memory_under_4gb": true,
    "response_time_under_500ms": true,
    "error_rate_under_0_1_percent": true
  }
}
```

## ğŸ—ï¸ ãƒ†ã‚¹ãƒˆå®Ÿè£…æˆ¦ç•¥

### **Phase 1: åŸºç›¤ãƒ†ã‚¹ãƒˆï¼ˆæ—¢å­˜ãƒ‘ã‚¿ãƒ¼ãƒ³æ´»ç”¨ï¼‰**

#### 1.1 ã‚ªãƒ•ãƒ©ã‚¤ãƒ³åŒæœŸAPIãƒ‘ã‚¿ãƒ¼ãƒ³é©ç”¨
```python
# tests/load/test_offline_sync_pattern.py
# æ—¢å­˜ã®11å€‹å…¨æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’100äººè¦æ¨¡ã«é©ç”¨

async def test_100_students_offline_sync():
    """ã‚ªãƒ•ãƒ©ã‚¤ãƒ³åŒæœŸAPIã®æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’100äººè¦æ¨¡ã§é©ç”¨"""
    # æ—¢å­˜æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³: ãƒ¢ãƒƒã‚¯æˆ»ã‚Šå€¤ã®å®Ÿè£…æ•´åˆæ€§
    # æ—¢å­˜æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³: ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã®æ­£ç¢ºãªæŠŠæ¡
    # æ—¢å­˜æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³: ä½“ç³»çš„ãªã‚¨ãƒ©ãƒ¼è§£æ±º

    students = generate_test_students(100)
    offline_events = []

    for student in students:
        events = simulate_offline_session(student, duration_minutes=30)
        offline_events.extend(events)

    # ãƒãƒƒãƒåŒæœŸå®Ÿè¡Œ
    sync_results = await bulk_sync_offline_events(offline_events)

    # æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œè¨¼
    assert all(result.success for result in sync_results)
    assert len(sync_results) == len(offline_events)
```

#### 1.2 LMSçµ±åˆãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³é©ç”¨
```python
# tests/load/test_lms_integration_pattern.py
# æ—¢å­˜ã®9å€‹å…¨æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’100äººè¦æ¨¡ã«é©ç”¨

async def test_100_students_lms_integration():
    """LMSçµ±åˆãƒ†ã‚¹ãƒˆã®æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’100äººè¦æ¨¡ã§é©ç”¨"""
    # æ—¢å­˜æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³: å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„ã‚¨ãƒ©ãƒ¼ä¿®æ­£
    # æ—¢å­˜æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³: ãƒ¦ãƒ‹ãƒ¼ã‚¯åˆ¶ç´„ã‚¨ãƒ©ãƒ¼ä¿®æ­£
    # æ—¢å­˜æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³: IntegrityErrorå‡¦ç†

    # 100äººåˆ†ã®ã‚¯ãƒ©ã‚¹ãƒ»èª²é¡Œãƒ»æå‡ºãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    classes = create_test_classes(5)  # 5ã‚¯ãƒ©ã‚¹
    assignments = create_test_assignments(classes, 10)  # ã‚¯ãƒ©ã‚¹ã‚ãŸã‚Š10èª²é¡Œ
    students = create_test_students(100)

    # å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿æŠ•å…¥
    submissions = []
    for student in students:
        for assignment in assignments:
            submission = create_test_submission(student, assignment)
            submissions.append(submission)

    # ãƒãƒƒãƒå‡¦ç†å®Ÿè¡Œ
    results = await bulk_create_submissions(submissions)

    # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æ¤œè¨¼ï¼ˆæ—¢å­˜æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
    assert_lms_data_integrity(results)
```

#### 1.3 WebSocketçµ±åˆãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³é©ç”¨
```python
# tests/load/test_websocket_integration_pattern.py
# æ—¢å­˜ã®13å€‹å…¨æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’100äººè¦æ¨¡ã«é©ç”¨

async def test_100_students_websocket_integration():
    """WebSocketçµ±åˆãƒ†ã‚¹ãƒˆã®æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’100äººè¦æ¨¡ã§é©ç”¨"""
    # æ—¢å­˜æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³: ConnectionManagerç›´æ¥ãƒ†ã‚¹ãƒˆ
    # æ—¢å­˜æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³: éåŒæœŸå‡¦ç†å¯¾å¿œ
    # æ—¢å­˜æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

    # 100äººåŒæ™‚WebSocketæ¥ç¶š
    connections = []
    for i in range(100):
        connection = await create_websocket_connection(f"student_{i:03d}")
        connections.append(connection)

    # å¤§é‡ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆãƒ†ã‚¹ãƒˆ
    test_messages = generate_test_messages(1000)

    start_time = time.time()
    for message in test_messages:
        await manager.broadcast(message)
    execution_time = time.time() - start_time

    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¤œè¨¼
    assert execution_time < 10.0  # 10ç§’ä»¥å†…
    assert all(conn.is_alive for conn in connections)
```

### **Phase 2: å¤§è¦æ¨¡è² è·ãƒ†ã‚¹ãƒˆ**

#### 2.1 æ®µéšçš„è² è·ãƒ†ã‚¹ãƒˆ
```python
# tests/load/test_phased_load.py

@pytest.mark.parametrize("student_count", [10, 25, 50, 75, 100])
async def test_phased_student_load(student_count):
    """æ®µéšçš„è² è·ãƒ†ã‚¹ãƒˆï¼š10â†’25â†’50â†’75â†’100äºº"""

    # æ—¢å­˜æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®é©ç”¨
    students = generate_realistic_students(student_count)

    # å®Ÿæ•™å®¤ç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    classroom = ClassroomSimulator(
        students=students,
        session_duration_minutes=90,
        cell_execution_pattern="realistic",
        error_injection_rate=0.15  # 15%ã®ã‚¨ãƒ©ãƒ¼ç‡
    )

    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š
    metrics = await classroom.run_with_monitoring()

    # æ®µéšåˆ¥æˆåŠŸåŸºæº–
    expected_throughput = student_count * 10  # å­¦ç”Ÿã‚ãŸã‚Š10ã‚¤ãƒ™ãƒ³ãƒˆ/ç§’
    assert metrics.throughput >= expected_throughput
    assert metrics.error_rate <= 0.001  # 0.1%ä»¥ä¸‹
```

#### 2.2 ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ãƒ†ã‚¹ãƒˆ
```python
# tests/load/test_realtime_monitoring.py

class RealtimeMonitor:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–"""

    async def test_resource_monitoring_under_load(self):
        """100äººè² è·æ™‚ã®ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–"""

        # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®š
        baseline = await self.collect_system_metrics()

        # 100äººåŒæ™‚è² è·å®Ÿè¡Œ
        load_task = asyncio.create_task(
            self.simulate_100_students_concurrent()
        )

        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–
        metrics_history = []
        while not load_task.done():
            current_metrics = await self.collect_system_metrics()
            metrics_history.append(current_metrics)
            await asyncio.sleep(1.0)

        # çµæœåˆ†æ
        peak_metrics = max(metrics_history, key=lambda m: m.memory_usage)

        # æ—¢å­˜æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®åŸºæº–é©ç”¨
        assert peak_metrics.memory_usage - baseline.memory_usage < 2048  # 2GBä»¥å†…
        assert peak_metrics.cpu_usage < 80  # 80%ä»¥å†…
        assert peak_metrics.redis_connections < 200  # 200æ¥ç¶šä»¥å†…
```

### **Phase 3: ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒ†ã‚¹ãƒˆ**

#### 3.1 PostgreSQL-InfluxDBæ•´åˆæ€§ãƒ†ã‚¹ãƒˆ
```python
# tests/integration/test_database_consistency.py

async def test_postgresql_influxdb_consistency_100_students():
    """100äººåˆ†ãƒ‡ãƒ¼ã‚¿ã®PostgreSQL-InfluxDBæ•´åˆæ€§æ¤œè¨¼"""

    # æ—¢å­˜æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³: å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„å‡¦ç†
    # æ—¢å­˜æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³: ãƒ‡ãƒ¼ã‚¿åŒæœŸç¢ºä¿

    # 100äººåˆ†ã®å¤§è¦æ¨¡ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    test_events = []
    for student_id in range(1, 101):
        student_events = generate_student_session_events(
            student_id=f"student_{student_id:03d}",
            session_duration_minutes=90,
            notebooks_count=3,
            cells_per_notebook=25
        )
        test_events.extend(student_events)

    # ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿æŠ•å…¥
    await bulk_insert_events(test_events)

    # PostgreSQLæ¤œè¨¼
    pg_stats = await get_postgresql_statistics()

    # InfluxDBæ¤œè¨¼
    influx_stats = await get_influxdb_statistics()

    # æ•´åˆæ€§æ¤œè¨¼ï¼ˆæ—¢å­˜æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
    assert pg_stats.student_count == 100
    assert pg_stats.student_count == influx_stats.unique_students
    assert pg_stats.total_executions == influx_stats.total_events
    assert abs(pg_stats.total_duration - influx_stats.total_duration) < 1000  # 1ç§’ä»¥å†…ã®èª¤å·®
```

#### 3.2 ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³æ•´åˆæ€§ãƒ†ã‚¹ãƒˆ
```python
# tests/integration/test_transaction_consistency.py

async def test_transaction_consistency_under_load():
    """é«˜è² è·æ™‚ã®ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³æ•´åˆæ€§"""

    # æ—¢å­˜æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³: å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„ã‚¨ãƒ©ãƒ¼å‡¦ç†
    # æ—¢å­˜æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³: åŒæ™‚å®Ÿè¡Œåˆ¶å¾¡

    # åŒæ™‚ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
    tasks = []
    for i in range(100):
        task = asyncio.create_task(
            execute_student_transaction(f"student_{i:03d}")
        )
        tasks.append(task)

    # å…¨ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å®Œäº†å¾…æ©Ÿ
    results = await asyncio.gather(*tasks, return_exceptions=True)

    # æ•´åˆæ€§æ¤œè¨¼
    successful_results = [r for r in results if not isinstance(r, Exception)]
    failed_results = [r for r in results if isinstance(r, Exception)]

    # æˆåŠŸç‡æ¤œè¨¼
    success_rate = len(successful_results) / len(results)
    assert success_rate >= 0.95  # 95%ä»¥ä¸Šã®æˆåŠŸç‡

    # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æ¤œè¨¼
    await verify_database_consistency()
```

### **Phase 4: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ»å¾©æ—§ãƒ†ã‚¹ãƒˆ**

#### 4.1 éšœå®³æ³¨å…¥ãƒ†ã‚¹ãƒˆ
```python
# tests/resilience/test_fault_injection.py

class FaultInjectionTest:
    """éšœå®³æ³¨å…¥ãƒ†ã‚¹ãƒˆ"""

    async def test_redis_failure_recovery(self):
        """Rediséšœå®³æ™‚ã®å¾©æ—§ãƒ†ã‚¹ãƒˆ"""

        # æ­£å¸¸çŠ¶æ…‹ã§100äººè² è·é–‹å§‹
        load_task = asyncio.create_task(
            self.simulate_100_students_load()
        )

        # 30ç§’å¾Œã«Rediséšœå®³æ³¨å…¥
        await asyncio.sleep(30)
        await self.inject_redis_failure()

        # 30ç§’å¾Œã«Rediså¾©æ—§
        await asyncio.sleep(30)
        await self.recover_redis()

        # è² è·ãƒ†ã‚¹ãƒˆå®Œäº†å¾…æ©Ÿ
        results = await load_task

        # å¾©æ—§å¾Œã®æ•´åˆæ€§æ¤œè¨¼
        assert results.data_loss_count == 0  # ãƒ‡ãƒ¼ã‚¿æå¤±ãªã—
        assert results.recovery_time < 60  # 60ç§’ä»¥å†…ã®å¾©æ—§
```

#### 4.2 ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ
```python
# tests/resilience/test_memory_leak.py

async def test_long_running_memory_stability():
    """é•·æ™‚é–“å®Ÿè¡Œæ™‚ã®ãƒ¡ãƒ¢ãƒªå®‰å®šæ€§ãƒ†ã‚¹ãƒˆ"""

    initial_memory = psutil.Process().memory_info().rss

    # 4æ™‚é–“ã®é€£ç¶šè² è·ãƒ†ã‚¹ãƒˆ
    for hour in range(4):
        await self.simulate_100_students_hour_session()

        current_memory = psutil.Process().memory_info().rss
        memory_growth = current_memory - initial_memory

        # ãƒ¡ãƒ¢ãƒªå¢—åŠ é‡ãƒã‚§ãƒƒã‚¯
        assert memory_growth < 512 * 1024 * 1024  # 512MBä»¥å†…

        # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        import gc
        gc.collect()
```

## ğŸ”§ å®Ÿè¡Œç’°å¢ƒãƒ»ãƒ„ãƒ¼ãƒ«

### **Dockerç’°å¢ƒè¨­å®š**
```yaml
# docker-compose.test.yml
version: '3.8'
services:
  test-runner:
    build:
      context: ./fastapi_server
      dockerfile: Dockerfile.test
    environment:
      - POSTGRES_URL=postgresql://test:test@postgres:5432/test_db
      - REDIS_URL=redis://redis:6379
      - INFLUXDB_URL=http://influxdb:8086
    depends_on:
      - postgres
      - redis
      - influxdb
    volumes:
      - ./test_results:/app/test_results
```

### **ç›£è¦–ãƒ„ãƒ¼ãƒ«çµ±åˆ**
```python
# tests/utils/monitoring.py

class TestMonitoring:
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œç›£è¦–"""

    def __init__(self):
        self.prometheus_client = PrometheusClient()
        self.grafana_client = GrafanaClient()

    async def start_monitoring(self):
        """ç›£è¦–é–‹å§‹"""
        await self.prometheus_client.start_scraping()
        await self.grafana_client.create_test_dashboard()

    async def collect_metrics(self):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
        return {
            "cpu_usage": psutil.cpu_percent(),
            "memory_usage": psutil.virtual_memory().percent,
            "redis_connections": await self.get_redis_connections(),
            "postgres_connections": await self.get_postgres_connections(),
            "response_times": await self.get_response_times()
        }
```

## ğŸ“Š æˆåŠŸåŸºæº–ãƒ»KPI

### **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŸºæº–**
| æŒ‡æ¨™ | ç›®æ¨™å€¤ | æ¸¬å®šæ–¹æ³• |
|------|--------|----------|
| ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ | 1000ã‚¤ãƒ™ãƒ³ãƒˆ/ç§’ä»¥ä¸Š | Redis Pub/Subç›£è¦– |
| ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ | 95%ile 500msä»¥å†… | APIãƒ¬ã‚¹ãƒãƒ³ã‚¹æ¸¬å®š |
| ã‚¨ãƒ©ãƒ¼ç‡ | 0.1%ä»¥ä¸‹ | å¤±æ•—ã‚¤ãƒ™ãƒ³ãƒˆ/ç·ã‚¤ãƒ™ãƒ³ãƒˆ |
| CPUä½¿ç”¨ç‡ | 80%ä»¥ä¸‹ | psutilç›£è¦– |
| ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ | 4GBä»¥ä¸‹ | psutilç›£è¦– |

### **ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§åŸºæº–**
| æŒ‡æ¨™ | ç›®æ¨™å€¤ | æ¤œè¨¼æ–¹æ³• |
|------|--------|----------|
| ãƒ‡ãƒ¼ã‚¿æå¤± | 0ä»¶ | PostgreSQL-InfluxDBæ¯”è¼ƒ |
| é‡è¤‡ãƒ‡ãƒ¼ã‚¿ | 0ä»¶ | ãƒ¦ãƒ‹ãƒ¼ã‚¯åˆ¶ç´„æ¤œè¨¼ |
| æ•´åˆæ€§ä¸€è‡´ç‡ | 100% | ã‚¯ãƒ­ã‚¹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œè¨¼ |

### **å¯ç”¨æ€§åŸºæº–**
| æŒ‡æ¨™ | ç›®æ¨™å€¤ | æ¸¬å®šæ–¹æ³• |
|------|--------|----------|
| ç¨¼åƒç‡ | 99.9%ä»¥ä¸Š | ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ç›£è¦– |
| å¾©æ—§æ™‚é–“ | 60ç§’ä»¥å†… | éšœå®³æ³¨å…¥ãƒ†ã‚¹ãƒˆ |
| ãƒ‡ãƒ¼ã‚¿å¾©æ—§ç‡ | 100% | ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¾©æ—§ãƒ†ã‚¹ãƒˆ |

## ğŸš€ å®Ÿè¡Œè¨ˆç”»

### **Week 1: åŸºç›¤ãƒ†ã‚¹ãƒˆå®Ÿè£…**
- [ ] Phase 1ãƒ†ã‚¹ãƒˆå®Ÿè£…ï¼ˆæ—¢å­˜ãƒ‘ã‚¿ãƒ¼ãƒ³é©ç”¨ï¼‰
- [ ] Dockerç’°å¢ƒæ§‹ç¯‰
- [ ] ç›£è¦–ãƒ„ãƒ¼ãƒ«çµ±åˆ

### **Week 2: è² è·ãƒ†ã‚¹ãƒˆå®Ÿè£…**
- [ ] Phase 2ãƒ†ã‚¹ãƒˆå®Ÿè£…ï¼ˆæ®µéšçš„è² è·ï¼‰
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–å®Ÿè£…
- [ ] è‡ªå‹•åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆ

### **Week 3: æ•´åˆæ€§ãƒ»å¾©æ—§ãƒ†ã‚¹ãƒˆå®Ÿè£…**
- [ ] Phase 3ãƒ†ã‚¹ãƒˆå®Ÿè£…ï¼ˆãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ï¼‰
- [ ] Phase 4ãƒ†ã‚¹ãƒˆå®Ÿè£…ï¼ˆéšœå®³å¾©æ—§ï¼‰
- [ ] ç·åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

### **Week 4: æœ€é©åŒ–ãƒ»ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŒ–**
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
- [ ] ãƒ†ã‚¹ãƒˆçµæœåˆ†æãƒ»ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
- [ ] é‹ç”¨ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ä½œæˆ

## ğŸ¯ æœŸå¾…ã•ã‚Œã‚‹æˆæœ

1. **å“è³ªä¿è¨¼**: 100äººåŒæ™‚ç’°å¢ƒã§ã®å®‰å®šå‹•ä½œä¿è¨¼
2. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–**: ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ç‰¹å®šã¨æ”¹å–„
3. **é‹ç”¨æŒ‡é‡**: æœ¬ç•ªç’°å¢ƒé‹ç”¨ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ç¢ºç«‹
4. **ç¶™ç¶šçš„æ”¹å–„**: ç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆä½“åˆ¶ã®æ§‹ç¯‰

ã“ã®åŒ…æ‹¬çš„ãªãƒ†ã‚¹ãƒˆè¨ˆç”»ã«ã‚ˆã‚Šã€æ—¢å­˜ã®186å€‹ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹æˆåŠŸã®å®Ÿç¸¾ã‚’åŸºç›¤ã¨ã—ã¦ã€100äººè¦æ¨¡ã®å®Ÿæ•™å®¤ç’°å¢ƒã§ã‚‚å®‰å®šã—ãŸã‚·ã‚¹ãƒ†ãƒ é‹ç”¨ãŒä¿è¨¼ã•ã‚Œã¾ã™ã€‚
