#!/usr/bin/env python3
"""
Redisæ¥ç¶šãƒ—ãƒ¼ãƒ«æœ€é©åŒ–ã®åŠ¹æœã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Phase 1ã®æ”¹å–„åŠ¹æœã‚’æ¤œè¨¼
"""

import asyncio
import aiohttp
import time
import json
from typing import List
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

FASTAPI_URL = "http://localhost:8000"

async def send_event_batch(session: aiohttp.ClientSession, batch_id: int, events_count: int = 5):
    """ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒƒãƒã‚’é€ä¿¡"""
    events = []
    for i in range(events_count):
        event = {
            "userId": f"student{batch_id}_{i}",
            "userName": f"Test Student {batch_id}_{i}",
            "notebookPath": "/test/notebook.ipynb",
            "cellId": f"cell_{i}",
            "eventType": "cell_executed",
            "cellSource": f"print('Test {batch_id}_{i}')",
            "cellOutput": f"Test {batch_id}_{i}",
            "executionCount": i + 1,
            "executionTime": f"2025-08-16T05:00:{i:02d}.000Z",
            "sessionId": f"session_{batch_id}",
            "kernelId": f"kernel_{batch_id}"
        }
        events.append(event)
    
    try:
        start_time = time.time()
        async with session.post(
            f"{FASTAPI_URL}/api/v1/events",
            json=events,
            headers={"Content-Type": "application/json"}
        ) as response:
            end_time = time.time()
            response_time = (end_time - start_time) * 1000  # ms
            
            if response.status == 202:
                result = await response.json()
                return {
                    "batch_id": batch_id,
                    "success": True,
                    "response_time_ms": response_time,
                    "events_count": events_count,
                    "batch_stats": result.get("batch_stats", {})
                }
            else:
                return {
                    "batch_id": batch_id,
                    "success": False,
                    "response_time_ms": response_time,
                    "error": f"HTTP {response.status}"
                }
    except Exception as e:
        return {
            "batch_id": batch_id,
            "success": False,
            "error": str(e)
        }

async def run_concurrent_test(concurrent_users: int = 50, events_per_user: int = 5):
    """åŒæ™‚æ¥ç¶šãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    logger.info(f"é–‹å§‹: {concurrent_users}ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€å„{events_per_user}ã‚¤ãƒ™ãƒ³ãƒˆ")
    
    connector = aiohttp.TCPConnector(
        limit=100,  # ç·æ¥ç¶šæ•°åˆ¶é™
        limit_per_host=50,  # ãƒ›ã‚¹ãƒˆæ¯æ¥ç¶šæ•°åˆ¶é™
        keepalive_timeout=30
    )
    
    async with aiohttp.ClientSession(connector=connector) as session:
        # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
        try:
            async with session.get(f"{FASTAPI_URL}/api/v1/health") as response:
                if response.status != 200:
                    logger.error("ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å¤±æ•—")
                    return
                logger.info("ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯æˆåŠŸ")
        except Exception as e:
            logger.error(f"ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å¤±æ•—: {e}")
            return
        
        # åŒæ™‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆå®Ÿè¡Œ
        start_time = time.time()
        tasks = [
            send_event_batch(session, i, events_per_user) 
            for i in range(concurrent_users)
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        end_time = time.time()
        
        # çµæœåˆ†æ
        total_time = end_time - start_time
        successful_requests = sum(1 for r in results if isinstance(r, dict) and r.get("success"))
        failed_requests = len(results) - successful_requests
        
        response_times = [
            r["response_time_ms"] for r in results 
            if isinstance(r, dict) and "response_time_ms" in r
        ]
        
        if response_times:
            avg_response_time = sum(response_times) / len(response_times)
            max_response_time = max(response_times)
            min_response_time = min(response_times)
        else:
            avg_response_time = max_response_time = min_response_time = 0
        
        # çµæœãƒ¬ãƒãƒ¼ãƒˆ
        total_events = concurrent_users * events_per_user
        events_per_second = total_events / total_time if total_time > 0 else 0
        
        print("\n" + "="*60)
        print("ğŸš€ Redisæ¥ç¶šãƒ—ãƒ¼ãƒ«æœ€é©åŒ–ãƒ†ã‚¹ãƒˆçµæœ")
        print("="*60)
        print(f"åŒæ™‚ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {concurrent_users}")
        print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¯ã‚¤ãƒ™ãƒ³ãƒˆæ•°: {events_per_user}")
        print(f"ç·ã‚¤ãƒ™ãƒ³ãƒˆæ•°: {total_events}")
        print(f"ç·å®Ÿè¡Œæ™‚é–“: {total_time:.2f}ç§’")
        print(f"ã‚¤ãƒ™ãƒ³ãƒˆ/ç§’: {events_per_second:.2f}")
        print(f"æˆåŠŸãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {successful_requests}")
        print(f"å¤±æ•—ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {failed_requests}")
        print(f"æˆåŠŸç‡: {(successful_requests/len(results)*100):.1f}%")
        print()
        print("â±ï¸ ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“çµ±è¨ˆ:")
        print(f"  å¹³å‡: {avg_response_time:.2f}ms")
        print(f"  æœ€å¤§: {max_response_time:.2f}ms")
        print(f"  æœ€å°: {min_response_time:.2f}ms")
        print()
        
        # ã‚¨ãƒ©ãƒ¼è©³ç´°
        errors = [r for r in results if isinstance(r, dict) and not r.get("success")]
        if errors:
            print("âŒ ã‚¨ãƒ©ãƒ¼è©³ç´°:")
            error_counts = {}
            for error in errors[:5]:  # æœ€åˆã®5å€‹ã®ã‚¨ãƒ©ãƒ¼ã‚’è¡¨ç¤º
                error_msg = error.get("error", "Unknown error")
                error_counts[error_msg] = error_counts.get(error_msg, 0) + 1
                print(f"  - {error_msg}")
            print()
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ¤å®š
        print("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡:")
        if successful_requests == len(results):
            print("  âœ… å…¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆæˆåŠŸ")
        elif successful_requests >= len(results) * 0.95:
            print("  ğŸŸ¡ é«˜æˆåŠŸç‡ (95%+)")
        else:
            print("  âŒ ä½æˆåŠŸç‡ (<95%)")
            
        if avg_response_time < 100:
            print("  âœ… é«˜é€Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ (<100ms)")
        elif avg_response_time < 500:
            print("  ğŸŸ¡ è¨±å®¹ãƒ¬ã‚¹ãƒãƒ³ã‚¹ (<500ms)")
        else:
            print("  âŒ ä½é€Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ (>=500ms)")
            
        if events_per_second > 100:
            print("  âœ… é«˜ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ (>100 events/sec)")
        elif events_per_second > 50:
            print("  ğŸŸ¡ ä¸­ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ (>50 events/sec)")
        else:
            print("  âŒ ä½ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ (<=50 events/sec)")
        
        print("="*60)

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("Redisæ¥ç¶šãƒ—ãƒ¼ãƒ«æœ€é©åŒ–åŠ¹æœãƒ†ã‚¹ãƒˆ")
    print("æ®µéšçš„ã«è² è·ã‚’å¢—ã‚„ã—ã¦ãƒ†ã‚¹ãƒˆã—ã¾ã™...\n")
    
    # æ®µéšçš„ãƒ†ã‚¹ãƒˆ
    test_cases = [
        (10, 5),   # 10ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€å„5ã‚¤ãƒ™ãƒ³ãƒˆ
        (25, 5),   # 25ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€å„5ã‚¤ãƒ™ãƒ³ãƒˆ  
        (50, 5),   # 50ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€å„5ã‚¤ãƒ™ãƒ³ãƒˆ
        (100, 3),  # 100ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€å„3ã‚¤ãƒ™ãƒ³ãƒˆ
    ]
    
    for users, events in test_cases:
        await run_concurrent_test(users, events)
        print(f"\nâ³ æ¬¡ã®ãƒ†ã‚¹ãƒˆã¾ã§3ç§’å¾…æ©Ÿ...\n")
        await asyncio.sleep(3)
    
    print("ğŸ‰ å…¨ãƒ†ã‚¹ãƒˆå®Œäº†!")

if __name__ == "__main__":
    asyncio.run(main())