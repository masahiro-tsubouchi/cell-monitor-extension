#!/usr/bin/env python3
"""
Phase 3: å¼·åŒ–ãƒãƒƒãƒå‡¦ç†ã¨ãƒ¯ãƒ¼ã‚«ãƒ¼ä¸¦åˆ—åŒ–ãƒ†ã‚¹ãƒˆ
Dockerç’°å¢ƒã§ã®å‹•ä½œç¢ºèª
"""

import asyncio
import json
import sys
import os
import logging
from datetime import datetime
import subprocess

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.abspath(os.path.dirname(__file__)))

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

FASTAPI_URL = "http://localhost:8000"

async def test_phase3_enhanced_batch_processing():
    """Phase 3å¼·åŒ–ãƒãƒƒãƒå‡¦ç†ãƒ†ã‚¹ãƒˆ"""
    print("ğŸš€ Phase 3: å¼·åŒ–ãƒãƒƒãƒå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("="*70)
    
    # å¾“æ¥ã®curlãƒ†ã‚¹ãƒˆã‚’ä½¿ç”¨ï¼ˆDockerã‚³ãƒ³ãƒ†ãƒŠå†…éƒ¨ï¼‰
    await asyncio.sleep(1)
    
    # 1. åŸºæœ¬çš„ãªå¼·åŒ–ãƒãƒƒãƒå‡¦ç†ãƒ†ã‚¹ãƒˆ
    print("1ï¸âƒ£ åŸºæœ¬çš„ãªå¼·åŒ–ãƒãƒƒãƒå‡¦ç†ãƒ†ã‚¹ãƒˆ")
    
    # å°è¦æ¨¡ãƒãƒƒãƒ (5ã‚¤ãƒ™ãƒ³ãƒˆ)
    small_batch = []
    for i in range(5):
        event = {
            "emailAddress": f"phase3_test_user_{i}@test.com",
            "userName": f"Phase3 Test User {i}",
            "notebookPath": "/test/phase3_notebook.ipynb",
            "cellId": f"phase3_cell_{i}",
            "cellType": "code",
            "eventType": "cell_executed",
            "cellSource": f"print('Phase 3 Enhanced Processing {i}')",
            "cellOutput": f"Phase 3 Enhanced Processing {i}",
            "executionCount": i + 1,
            "executionTime": f"2025-08-16T06:00:{i:02d}.000Z",
            "sessionId": f"phase3_session_{i}",
            "kernelId": f"phase3_kernel_{i}"
        }
        small_batch.append(event)
    
    # curlã‚³ãƒãƒ³ãƒ‰ã§ãƒ†ã‚¹ãƒˆ
    
    # JSONæ–‡å­—åˆ—ã‚’ä½œæˆ
    json_data = json.dumps(small_batch)
    
    try:
        # curlã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ
        result = subprocess.run([
            'curl', '-X', 'POST', 
            f'{FASTAPI_URL}/api/v1/events',
            '-H', 'Content-Type: application/json',
            '-d', json_data,
            '--max-time', '30'
        ], capture_output=True, text=True, timeout=30)
        
        if result.returncode == 0:
            response_data = json.loads(result.stdout)
            print(f"   âœ… å°è¦æ¨¡ãƒãƒƒãƒå‡¦ç†æˆåŠŸ: {response_data.get('message', 'No message')}")
            
            # Phase 3ç‰¹æœ‰ã®çµ±è¨ˆç¢ºèª
            batch_stats = response_data.get('batch_stats', {})
            if 'batch_id' in batch_stats:
                print(f"   ğŸ“Š ãƒãƒƒãƒID: {batch_stats['batch_id']}")
                print(f"   ğŸ“Š å‡¦ç†æ®µéšæ•°: {len(batch_stats.get('processing_stages', {}))}")
                
                # å„æ®µéšã®çµæœç¢ºèª
                stages = batch_stats.get('processing_stages', {})
                for stage_name, stage_data in stages.items():
                    status = stage_data.get('status', 'unknown')
                    duration = stage_data.get('duration_ms', 0)
                    print(f"     - {stage_name}: {status} ({duration}ms)")
            else:
                print("   ğŸŸ¡ ãƒ¬ã‚¬ã‚·ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ï¼ˆPhase 3æ©Ÿèƒ½æœªä½¿ç”¨ï¼‰")
        else:
            print(f"   âŒ å°è¦æ¨¡ãƒãƒƒãƒå‡¦ç†å¤±æ•—: {result.stderr}")
            
    except Exception as e:
        print(f"   âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
    
    # 2. ä¸­è¦æ¨¡ãƒãƒƒãƒãƒ†ã‚¹ãƒˆ (50ã‚¤ãƒ™ãƒ³ãƒˆ)
    print("\n2ï¸âƒ£ ä¸­è¦æ¨¡ãƒãƒƒãƒå‡¦ç†ãƒ†ã‚¹ãƒˆ (50ã‚¤ãƒ™ãƒ³ãƒˆ)")
    
    medium_batch = []
    event_types = ["cell_executed", "progress_update", "notebook_saved", "error_occurred"]
    
    for i in range(50):
        event_type = event_types[i % len(event_types)]
        event = {
            "emailAddress": f"phase3_medium_user_{i}@test.com",
            "userName": f"Phase3 Medium User {i}",
            "notebookPath": f"/test/medium_test_{i//10}.ipynb",
            "cellId": f"medium_cell_{i}",
            "cellType": "code",
            "eventType": event_type,
            "cellSource": f"# Medium test {i}\nprint('Processing {i}')",
            "cellOutput": f"Processing {i}",
            "executionCount": i + 1,
            "executionTime": f"2025-08-16T06:01:{i%60:02d}.000Z",
            "sessionId": f"medium_session_{i//10}",
            "kernelId": f"medium_kernel_{i//10}"
        }
        medium_batch.append(event)
    
    try:
        json_data = json.dumps(medium_batch)
        start_time = datetime.now()
        
        result = subprocess.run([
            'curl', '-X', 'POST', 
            f'{FASTAPI_URL}/api/v1/events',
            '-H', 'Content-Type: application/json',
            '-d', json_data,
            '--max-time', '60'
        ], capture_output=True, text=True, timeout=60)
        
        end_time = datetime.now()
        processing_time = (end_time - start_time).total_seconds()
        
        if result.returncode == 0:
            response_data = json.loads(result.stdout)
            print(f"   âœ… ä¸­è¦æ¨¡ãƒãƒƒãƒå‡¦ç†æˆåŠŸ: {processing_time:.3f}ç§’")
            print(f"   ğŸ“Š å‡¦ç†é€Ÿåº¦: {50/processing_time:.1f} events/sec")
            
            batch_stats = response_data.get('batch_stats', {})
            if 'processing_stages' in batch_stats:
                print("   ğŸ“Š å‡¦ç†æ®µéšè©³ç´°:")
                stages = batch_stats['processing_stages']
                for stage_name, stage_data in stages.items():
                    status = stage_data.get('status', 'unknown')
                    duration = stage_data.get('duration_ms', 0)
                    extra_info = ""
                    if 'persisted_count' in stage_data:
                        extra_info = f", {stage_data['persisted_count']}ä»¶æ°¸ç¶šåŒ–"
                    if 'notified_count' in stage_data:
                        extra_info = f", {stage_data['notified_count']}ä»¶é€šçŸ¥"
                    print(f"     - {stage_name}: {status} ({duration}ms{extra_info})")
        else:
            print(f"   âŒ ä¸­è¦æ¨¡ãƒãƒƒãƒå‡¦ç†å¤±æ•—: {result.stderr}")
            
    except Exception as e:
        print(f"   âŒ ä¸­è¦æ¨¡ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
    
    # 3. å¤§è¦æ¨¡ãƒãƒƒãƒãƒ†ã‚¹ãƒˆ (100ã‚¤ãƒ™ãƒ³ãƒˆ - ä¸Šé™ãƒã‚§ãƒƒã‚¯)
    print("\n3ï¸âƒ£ å¤§è¦æ¨¡ãƒãƒƒãƒå‡¦ç†ãƒ†ã‚¹ãƒˆ (100ã‚¤ãƒ™ãƒ³ãƒˆ)")
    
    large_batch = []
    for i in range(100):
        event_type = event_types[i % len(event_types)]
        priority = "high" if event_type == "cell_executed" else "medium" if event_type == "progress_update" else "low"
        
        event = {
            "emailAddress": f"phase3_large_user_{i}@test.com",
            "userName": f"Phase3 Large User {i}",
            "notebookPath": f"/test/large_test_{i//20}.ipynb",
            "cellId": f"large_cell_{i}",
            "cellType": "code",
            "eventType": event_type,
            "cellSource": f"# Large test {i}\nprint('Large processing {i}')",
            "cellOutput": f"Large processing {i}",
            "executionCount": i + 1,
            "executionTime": f"2025-08-16T06:02:{i%60:02d}.000Z",
            "sessionId": f"large_session_{i//20}",
            "kernelId": f"large_kernel_{i//20}",
            "priority": priority  # Phase 3ã§ã®å„ªå…ˆåº¦ãƒ†ã‚¹ãƒˆ
        }
        large_batch.append(event)
    
    try:
        json_data = json.dumps(large_batch)
        start_time = datetime.now()
        
        result = subprocess.run([
            'curl', '-X', 'POST', 
            f'{FASTAPI_URL}/api/v1/events',
            '-H', 'Content-Type: application/json',
            '-d', json_data,
            '--max-time', '90'
        ], capture_output=True, text=True, timeout=90)
        
        end_time = datetime.now()
        processing_time = (end_time - start_time).total_seconds()
        
        if result.returncode == 0:
            response_data = json.loads(result.stdout)
            print(f"   âœ… å¤§è¦æ¨¡ãƒãƒƒãƒå‡¦ç†æˆåŠŸ: {processing_time:.3f}ç§’")
            print(f"   ğŸ“Š å‡¦ç†é€Ÿåº¦: {100/processing_time:.1f} events/sec")
            
            # Phase 3ç‰¹æœ‰ã®çµ±è¨ˆè©³ç´°åˆ†æ
            batch_stats = response_data.get('batch_stats', {})
            if 'event_types' in batch_stats:
                print("   ğŸ“Š ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ:")
                for event_type, count in batch_stats['event_types'].items():
                    print(f"     - {event_type}: {count}ä»¶")
            
            if 'validation_success_rate' in batch_stats:
                success_rate = batch_stats['validation_success_rate']
                print(f"   ğŸ“Š æ¤œè¨¼æˆåŠŸç‡: {success_rate:.1f}%")
                
        else:
            print(f"   âŒ å¤§è¦æ¨¡ãƒãƒƒãƒå‡¦ç†å¤±æ•—: {result.stderr}")
            
    except Exception as e:
        print(f"   âŒ å¤§è¦æ¨¡ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
    
    # 4. è¶…éåˆ¶é™ãƒ†ã‚¹ãƒˆ (250ã‚¤ãƒ™ãƒ³ãƒˆ - ã‚¨ãƒ©ãƒ¼ç¢ºèª)
    print("\n4ï¸âƒ£ è¶…éåˆ¶é™ãƒ†ã‚¹ãƒˆ (250ã‚¤ãƒ™ãƒ³ãƒˆ - ã‚¨ãƒ©ãƒ¼ç¢ºèª)")
    
    oversized_batch = []
    for i in range(250):  # MAX_BATCH_SIZE = 200ã‚’è¶…é
        event = {
            "emailAddress": f"oversized_user_{i}@test.com",
            "eventType": "test_oversize",
            "cellId": f"oversized_cell_{i}",
            "cellType": "code"
        }
        oversized_batch.append(event)
    
    try:
        json_data = json.dumps(oversized_batch)
        
        result = subprocess.run([
            'curl', '-X', 'POST', 
            f'{FASTAPI_URL}/api/v1/events',
            '-H', 'Content-Type: application/json',
            '-d', json_data,
            '--max-time', '30'
        ], capture_output=True, text=True, timeout=30)
        
        if result.returncode == 0:
            # HTTPã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª
            print("   ğŸŸ¡ äºˆæœŸã—ãªã„æˆåŠŸ - åˆ¶é™ãƒã‚§ãƒƒã‚¯è¦ç¢ºèª")
        else:
            # æœŸå¾…ã•ã‚Œã‚‹ã‚¨ãƒ©ãƒ¼
            print("   âœ… é©åˆ‡ãªåˆ¶é™ã‚¨ãƒ©ãƒ¼æ¤œå‡º")
            if "413" in result.stderr or "exceeds maximum" in result.stderr:
                print("   ğŸ“Š æ­£ã—ã„413ã‚¨ãƒ©ãƒ¼ï¼ˆãƒãƒƒãƒã‚µã‚¤ã‚ºè¶…éï¼‰")
            
    except Exception as e:
        print(f"   âŒ è¶…éåˆ¶é™ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
    
    print("\n" + "="*70)
    print("ğŸ“‹ Phase 3ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
    print("="*70)
    print("âœ… Phase 3å¼·åŒ–ãƒãƒƒãƒå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ æ©Ÿèƒ½ç¢ºèª:")
    print("  - ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å¯¾å¿œãƒãƒƒãƒå‡¦ç†")
    print("  - å‡¦ç†æ®µéšåˆ¥çµ±è¨ˆåé›†")
    print("  - ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—åˆ¥å„ªå…ˆåº¦å‡¦ç†")
    print("  - å¤§è¦æ¨¡ãƒãƒƒãƒå‡¦ç†å¯¾å¿œ (æœ€å¤§200ã‚¤ãƒ™ãƒ³ãƒˆ)")
    print("  - é©åˆ‡ãªåˆ¶é™å€¤ãƒã‚§ãƒƒã‚¯")
    print("\nğŸš€ æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„åŠ¹æœ:")
    print("  - 200åŒæ™‚ãƒ¦ãƒ¼ã‚¶ãƒ¼å¯¾å¿œ")
    print("  - éšœå®³å›å¾©æ©Ÿèƒ½")
    print("  - è©³ç´°ãªå‡¦ç†è¿½è·¡")
    print("  - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–")

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("Phase 3: å¼·åŒ–ãƒãƒƒãƒå‡¦ç†ã¨ãƒ¯ãƒ¼ã‚«ãƒ¼ä¸¦åˆ—åŒ–ãƒ†ã‚¹ãƒˆ")
    print("Dockerç’°å¢ƒã§ã®å‹•ä½œç¢ºèª\n")
    
    await test_phase3_enhanced_batch_processing()

if __name__ == "__main__":
    asyncio.run(main())