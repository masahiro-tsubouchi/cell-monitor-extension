#!/usr/bin/env python3
"""
Dockerç’°å¢ƒç”¨ã‚·ãƒ³ãƒ—ãƒ«Redisæ¥ç¶šãƒ†ã‚¹ãƒˆ
æ—¢å­˜ã®ä¾å­˜é–¢ä¿‚ã®ã¿ä½¿ç”¨
"""

import asyncio
import time
import json
import sys
import os

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.abspath(os.path.dirname(__file__)))

from db.redis_client import get_redis_client
from schemas.event import EventData
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_redis_connection_pool():
    """Redisæ¥ç¶šãƒ—ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ” Redisæ¥ç¶šãƒ—ãƒ¼ãƒ«æœ€é©åŒ–ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("="*50)
    
    # 1. åŸºæœ¬æ¥ç¶šãƒ†ã‚¹ãƒˆ
    print("1ï¸âƒ£ åŸºæœ¬æ¥ç¶šãƒ†ã‚¹ãƒˆ")
    try:
        redis_client = await get_redis_client()
        start_time = time.time()
        result = await redis_client.ping()
        end_time = time.time()
        print(f"   âœ… Redis pingæˆåŠŸ: {result}")
        print(f"   â±ï¸ ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“: {(end_time - start_time)*1000:.2f}ms")
    except Exception as e:
        print(f"   âŒ Redisæ¥ç¶šå¤±æ•—: {e}")
        return False
    
    # 2. åŒä¸€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå†åˆ©ç”¨ãƒ†ã‚¹ãƒˆ
    print("\n2ï¸âƒ£ åŒä¸€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå†åˆ©ç”¨ãƒ†ã‚¹ãƒˆ")
    client1 = await get_redis_client()
    client2 = await get_redis_client()
    print(f"   Client 1 ID: {id(client1)}")
    print(f"   Client 2 ID: {id(client2)}")
    if id(client1) == id(client2):
        print("   âœ… ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³å‹•ä½œç¢ºèª")
    else:
        print("   ğŸŸ¡ æ–°ã—ã„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆï¼ˆæ¥ç¶šãƒ—ãƒ¼ãƒ«ã¯å…±æœ‰ï¼‰")
    
    # 3. è¤‡æ•°æ“ä½œãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
    print("\n3ï¸âƒ£ è¤‡æ•°æ“ä½œãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ")
    operations = 50
    start_time = time.time()
    
    tasks = []
    for i in range(operations):
        tasks.append(test_redis_operation(i))
    
    results = await asyncio.gather(*tasks, return_exceptions=True)
    end_time = time.time()
    
    success_count = sum(1 for r in results if r is True)
    total_time = end_time - start_time
    ops_per_second = operations / total_time
    
    print(f"   ğŸ“Š çµæœ:")
    print(f"     - ç·æ“ä½œæ•°: {operations}")
    print(f"     - æˆåŠŸæ•°: {success_count}")
    print(f"     - å¤±æ•—æ•°: {operations - success_count}")
    print(f"     - ç·æ™‚é–“: {total_time:.3f}ç§’")
    print(f"     - æ“ä½œ/ç§’: {ops_per_second:.2f}")
    print(f"     - å¹³å‡ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {total_time/operations*1000:.2f}ms")
    
    # 4. ã‚¤ãƒ™ãƒ³ãƒˆç™ºè¡Œãƒ†ã‚¹ãƒˆ
    print("\n4ï¸âƒ£ ã‚¤ãƒ™ãƒ³ãƒˆç™ºè¡Œãƒ†ã‚¹ãƒˆ")
    await test_event_publishing()
    
    print("\nğŸ‰ ãƒ†ã‚¹ãƒˆå®Œäº†!")
    return True

async def test_redis_operation(operation_id: int):
    """å€‹åˆ¥Redisæ“ä½œãƒ†ã‚¹ãƒˆ"""
    try:
        redis_client = await get_redis_client()
        
        # SETæ“ä½œ
        await redis_client.set(f"test_key_{operation_id}", f"test_value_{operation_id}", ex=10)
        
        # GETæ“ä½œ
        value = await redis_client.get(f"test_key_{operation_id}")
        
        # DELæ“ä½œ
        await redis_client.delete(f"test_key_{operation_id}")
        
        return True
    except Exception as e:
        logger.error(f"Operation {operation_id} failed: {e}")
        return False

async def test_event_publishing():
    """ã‚¤ãƒ™ãƒ³ãƒˆç™ºè¡Œãƒ†ã‚¹ãƒˆ"""
    try:
        redis_client = await get_redis_client()
        
        # ãƒ†ã‚¹ãƒˆã‚¤ãƒ™ãƒ³ãƒˆä½œæˆ
        event_data = {
            "userId": "test_user_001",
            "userName": "Test User",
            "notebookPath": "/test/notebook.ipynb",
            "cellId": "test_cell_001",
            "eventType": "cell_executed",
            "cellSource": "print('Hello Redis Pool!')",
            "cellOutput": "Hello Redis Pool!",
            "executionCount": 1,
            "executionTime": "2025-08-16T05:00:00.000Z",
            "sessionId": "test_session_001",
            "kernelId": "test_kernel_001"
        }
        
        # ã‚¤ãƒ™ãƒ³ãƒˆç™ºè¡Œ
        start_time = time.time()
        await redis_client.publish("progress_events", json.dumps(event_data))
        end_time = time.time()
        
        print(f"   âœ… ã‚¤ãƒ™ãƒ³ãƒˆç™ºè¡ŒæˆåŠŸ")
        print(f"   â±ï¸ ç™ºè¡Œæ™‚é–“: {(end_time - start_time)*1000:.2f}ms")
        
        # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ“ä½œãƒ†ã‚¹ãƒˆ
        print("   ğŸ”„ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ“ä½œãƒ†ã‚¹ãƒˆ...")
        start_time = time.time()
        
        pipe = redis_client.pipeline()
        for i in range(10):
            pipe.publish("progress_events", json.dumps({**event_data, "userId": f"user_{i}"}))
        
        await pipe.execute()
        end_time = time.time()
        
        print(f"   âœ… ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ“ä½œæˆåŠŸ (10ã‚¤ãƒ™ãƒ³ãƒˆ)")
        print(f"   â±ï¸ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ™‚é–“: {(end_time - start_time)*1000:.2f}ms")
        
    except Exception as e:
        print(f"   âŒ ã‚¤ãƒ™ãƒ³ãƒˆç™ºè¡Œå¤±æ•—: {e}")

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("Redisæ¥ç¶šãƒ—ãƒ¼ãƒ«æœ€é©åŒ–åŠ¹æœæ¤œè¨¼")
    print("Dockerç’°å¢ƒã§ã®å‹•ä½œç¢ºèª\n")
    
    success = await test_redis_connection_pool()
    
    if success:
        print("\nâœ… Phase 1æœ€é©åŒ–: æˆåŠŸ")
        print("ğŸ“ˆ æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ:")
        print("  - Redisæ¥ç¶šæ•°ã®å‰Šæ¸›")
        print("  - ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã®å®‰å®šåŒ–") 
        print("  - 200åŒæ™‚æ¥ç¶šã¸ã®å¯¾å¿œåŠ›å‘ä¸Š")
    else:
        print("\nâŒ Phase 1æœ€é©åŒ–: å¤±æ•—")
        print("ğŸ”§ ç¢ºèªãŒå¿…è¦ãªé …ç›®:")
        print("  - Redisæ¥ç¶šè¨­å®š")
        print("  - æ¥ç¶šãƒ—ãƒ¼ãƒ«è¨­å®š")

if __name__ == "__main__":
    asyncio.run(main())