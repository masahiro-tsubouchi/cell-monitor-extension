#!/usr/bin/env python3
"""
100äººåˆ†ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å®Ÿéš›ã«APIã«é€ä¿¡ã—ã¦DBã«ä¿å­˜ã—ã€CSVã§å‡ºåŠ›ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import requests
import json
import time
import csv
import os
from datetime import datetime
from typing import List, Dict, Any
import psycopg2
from influxdb_client import InfluxDBClient
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker

# è¨­å®š
API_BASE_URL = "http://localhost:8000"
POSTGRES_URL = "postgresql://admin:secretpassword@postgres:5432/progress_db"
INFLUXDB_URL = "http://influxdb:8086"
INFLUXDB_TOKEN = "my-super-secret-token"
INFLUXDB_ORG = "my-org"
INFLUXDB_BUCKET = "jupyter_events"


def create_test_event(
    student_id: int, notebook_id: int, cell_id: int
) -> Dict[str, Any]:
    """ãƒ†ã‚¹ãƒˆã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
    return {
        "eventId": f"evt_{int(time.time() * 1000)}_{student_id}_{cell_id}",
        "eventType": "cell_executed",
        "eventTime": None,
        "userId": f"test_student_{student_id:03d}",
        "userName": f"Test Student {student_id:03d}",
        "sessionId": None,
        "notebookPath": f"/test_notebooks/notebook_{notebook_id:02d}.ipynb",
        "cellId": f"cell_{cell_id:03d}",
        "cellIndex": cell_id - 1,
        "cellType": "code",
        "code": f"print('Hello from student {student_id}, cell {cell_id}')",
        "executionCount": 1,
        "hasError": student_id % 7 == 0,  # 7äººã«1äººã¯ã‚¨ãƒ©ãƒ¼
        "errorMessage": (
            f"Test error for student {student_id}" if student_id % 7 == 0 else None
        ),
        "result": None,
        "executionDurationMs": 100 + (student_id % 50) * 10,
        "metadata": None,
    }


def send_events_to_api(events: List[Dict[str, Any]]) -> bool:
    """ã‚¤ãƒ™ãƒ³ãƒˆã‚’APIã«é€ä¿¡"""
    try:
        response = requests.post(
            f"{API_BASE_URL}/api/v1/events",
            json=events,
            headers={"Content-Type": "application/json"},
            timeout=30,
        )

        if response.status_code == 202:
            print(f"âœ… {len(events)}ä»¶ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’é€ä¿¡æˆåŠŸ")
            return True
        else:
            print(f"âŒ APIé€ä¿¡å¤±æ•—: {response.status_code} - {response.text}")
            return False

    except Exception as e:
        print(f"âŒ APIé€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
        return False


def wait_for_worker_processing(expected_count: int, max_wait_seconds: int = 60):
    """ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã®å‡¦ç†å®Œäº†ã‚’å¾…æ©Ÿ"""
    print(f"ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã®å‡¦ç†å®Œäº†ã‚’å¾…æ©Ÿä¸­... (æœ€å¤§{max_wait_seconds}ç§’)")

    engine = create_engine(POSTGRES_URL)

    for i in range(max_wait_seconds):
        try:
            with engine.connect() as conn:
                result = conn.execute(
                    text(
                        "SELECT COUNT(*) FROM cell_executions WHERE student_id IN (SELECT id FROM students WHERE user_id LIKE 'test_student_%')"
                    )
                )
                current_count = result.scalar()

                print(f"é€²è¡ŒçŠ¶æ³: {current_count}/{expected_count} ä»¶å‡¦ç†æ¸ˆã¿")

                if current_count >= expected_count:
                    print(f"âœ… å…¨{expected_count}ä»¶ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")
                    return True

        except Exception as e:
            print(f"DBç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")

        time.sleep(1)

    print(f"âš ï¸ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {max_wait_seconds}ç§’ä»¥å†…ã«å‡¦ç†ãŒå®Œäº†ã—ã¾ã›ã‚“ã§ã—ãŸ")
    return False


def export_postgresql_data():
    """PostgreSQLãƒ‡ãƒ¼ã‚¿ã‚’CSVã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    print("PostgreSQLãƒ‡ãƒ¼ã‚¿ã‚’CSVã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­...")

    engine = create_engine(POSTGRES_URL)
    output_dir = "/app/test_results"
    os.makedirs(output_dir, exist_ok=True)

    # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå¯¾è±¡ãƒ†ãƒ¼ãƒ–ãƒ«ã¨ã‚¯ã‚¨ãƒª
    exports = {
        "students": "SELECT * FROM students WHERE user_id LIKE 'test_student_%' ORDER BY id",
        "notebooks": "SELECT * FROM notebooks WHERE path LIKE '/test_notebooks/%' ORDER BY id",
        "cells": """
            SELECT c.* FROM cells c
            JOIN notebooks n ON c.notebook_id = n.id
            WHERE n.path LIKE '/test_notebooks/%'
            ORDER BY c.id
        """,
        "cell_executions": """
            SELECT ce.* FROM cell_executions ce
            JOIN students s ON ce.student_id = s.id
            WHERE s.user_id LIKE 'test_student_%'
            ORDER BY ce.id
        """,
    }

    for table_name, query in exports.items():
        try:
            with engine.connect() as conn:
                result = conn.execute(text(query))
                rows = result.fetchall()
                columns = result.keys()

                csv_path = f"{output_dir}/{table_name}_100_students.csv"
                with open(csv_path, "w", newline="", encoding="utf-8") as csvfile:
                    writer = csv.writer(csvfile)
                    writer.writerow(columns)
                    writer.writerows(rows)

                print(f"âœ… {table_name}: {len(rows)}ä»¶ â†’ {csv_path}")

        except Exception as e:
            print(f"âŒ {table_name}ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")


def export_influxdb_data():
    """InfluxDBãƒ‡ãƒ¼ã‚¿ã‚’CSVã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    print("InfluxDBãƒ‡ãƒ¼ã‚¿ã‚’CSVã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­...")

    try:
        # InfluxDBæ¥ç¶šï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
        if INFLUXDB_TOKEN == "your-token-here":
            print(
                "âš ï¸ InfluxDBãƒˆãƒ¼ã‚¯ãƒ³ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€InfluxDBã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™"
            )
            return

        client = InfluxDBClient(
            url=INFLUXDB_URL, token=INFLUXDB_TOKEN, org=INFLUXDB_ORG
        )
        query_api = client.query_api()

        # éå»1æ™‚é–“ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        query = f"""
        from(bucket: "{INFLUXDB_BUCKET}")
        |> range(start: -1h)
        |> filter(fn: (r) => r._measurement == "student_progress")
        |> filter(fn: (r) => r.userId =~ /test_student_/)
        """

        result = query_api.query(query)

        output_dir = "/app/test_results"
        csv_path = f"{output_dir}/influxdb_student_progress_100_students.csv"

        with open(csv_path, "w", newline="", encoding="utf-8") as csvfile:
            writer = csv.writer(csvfile)

            # ãƒ˜ãƒƒãƒ€ãƒ¼æ›¸ãè¾¼ã¿
            headers_written = False
            row_count = 0

            for table in result:
                for record in table.records:
                    if not headers_written:
                        headers = ["time", "measurement"] + list(record.values.keys())
                        writer.writerow(headers)
                        headers_written = True

                    row = [record.get_time(), record.get_measurement()] + list(
                        record.values.values()
                    )
                    writer.writerow(row)
                    row_count += 1

            print(f"âœ… InfluxDB: {row_count}ä»¶ â†’ {csv_path}")

    except Exception as e:
        print(f"âŒ InfluxDBã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸš€ 100äººåˆ†ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ»é€ä¿¡ãƒ»ä¿å­˜ãƒ»CSVå‡ºåŠ›ã‚’é–‹å§‹ã—ã¾ã™")

    # 1. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    print("\nğŸ“Š ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
    events = []

    for student_id in range(1, 101):  # 100äººã®å­¦ç”Ÿ
        for notebook_id in range(1, 6):  # 5ã¤ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯
            for cell_id in range(1, 4):  # å„ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã«3ã¤ã®ã‚»ãƒ«
                event = create_test_event(student_id, notebook_id, cell_id)
                events.append(event)

    total_events = len(events)
    print(f"âœ… {total_events}ä»¶ã®ãƒ†ã‚¹ãƒˆã‚¤ãƒ™ãƒ³ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ")

    # 2. APIã«é€ä¿¡ï¼ˆãƒãƒƒãƒå‡¦ç†ï¼‰
    print(f"\nğŸ“¤ {total_events}ä»¶ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’APIã«é€ä¿¡ä¸­...")
    batch_size = 50
    successful_batches = 0

    for i in range(0, total_events, batch_size):
        batch = events[i : i + batch_size]
        if send_events_to_api(batch):
            successful_batches += 1
        time.sleep(0.5)  # APIè² è·è»½æ¸›ã®ãŸã‚å°‘ã—å¾…æ©Ÿ

    print(f"âœ… {successful_batches}å€‹ã®ãƒãƒƒãƒã‚’é€ä¿¡å®Œäº†")

    # 3. ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã®å‡¦ç†å®Œäº†ã‚’å¾…æ©Ÿ
    print(f"\nâ³ ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã®å‡¦ç†å®Œäº†ã‚’å¾…æ©Ÿ...")
    wait_for_worker_processing(total_events, max_wait_seconds=120)

    # 4. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    print(f"\nğŸ“ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ...")
    export_postgresql_data()
    export_influxdb_data()

    print(f"\nğŸ‰ 100äººåˆ†ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    print(f"ğŸ“‚ çµæœã¯ /app/test_results ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™")


if __name__ == "__main__":
    main()
