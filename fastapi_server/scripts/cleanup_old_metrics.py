#!/usr/bin/env python3
"""
InfluxDBå¤ã„ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½¿ç”¨ä¾‹:
  # 90æ—¥ä»¥ä¸Šå‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
  python scripts/cleanup_old_metrics.py --days 90
  
  # ç‰¹å®šæœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
  python scripts/cleanup_old_metrics.py --start 2025-01-01 --end 2025-02-01
  
  # ç‰¹å®šå­¦ç”Ÿã®ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
  python scripts/cleanup_old_metrics.py --student student@example.com --days 30
  
  # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¢ãƒ¼ãƒ‰ï¼ˆå‰Šé™¤ã›ãšã«å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã®ã¿è¡¨ç¤ºï¼‰
  python scripts/cleanup_old_metrics.py --days 90 --dry-run
"""

import argparse
import logging
import sys
from datetime import datetime, timedelta
from typing import Optional, List
import os

# FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.config import settings

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

try:
    from influxdb_client import InfluxDBClient
    from influxdb_client.client.delete_api import DeleteApi
    from influxdb_client.client.query_api import QueryApi
    INFLUXDB_AVAILABLE = True
except ImportError:
    logger.warning("InfluxDB client not available. Install with: pip install influxdb-client")
    INFLUXDB_AVAILABLE = False


class InfluxDBMetricsCleanup:
    """InfluxDBå¤ã„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, dry_run: bool = False):
        self.dry_run = dry_run
        self.influx_client: Optional[InfluxDBClient] = None
        self.delete_api: Optional[DeleteApi] = None
        self.query_api: Optional[QueryApi] = None
        
        if not INFLUXDB_AVAILABLE:
            raise RuntimeError("InfluxDB client is not available")
        
        self._connect_to_influxdb()
    
    def _connect_to_influxdb(self):
        """InfluxDBã«æ¥ç¶š"""
        try:
            self.influx_client = InfluxDBClient(
                url=settings.DYNAMIC_INFLUXDB_URL,
                token=settings.INFLUXDB_TOKEN,
                org=settings.INFLUXDB_ORG
            )
            
            # API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
            self.delete_api = self.influx_client.delete_api()
            self.query_api = self.influx_client.query_api()
            
            # æ¥ç¶šãƒ†ã‚¹ãƒˆ
            health = self.influx_client.health()
            if health.status == "pass":
                logger.info("âœ… InfluxDBæ¥ç¶šæˆåŠŸ")
            else:
                raise RuntimeError(f"InfluxDBæ¥ç¶šå¤±æ•—: {health.message}")
                
        except Exception as e:
            logger.error(f"âŒ InfluxDBæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def cleanup_old_data(
        self, 
        days: Optional[int] = None,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        student_email: Optional[str] = None
    ) -> dict:
        """å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        
        # æ™‚é–“ç¯„å›²ã®è¨­å®š
        if days:
            start_time = datetime.utcnow() - timedelta(days=days)
            end_time = datetime.utcnow()
            logger.info(f"ğŸ—“ï¸ {days}æ—¥ä»¥ä¸Šå‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤å¯¾è±¡ã¨ã—ã¾ã™")
        elif start_date and end_date:
            start_time = datetime.fromisoformat(start_date)
            end_time = datetime.fromisoformat(end_date)
            logger.info(f"ğŸ—“ï¸ {start_date} ã‹ã‚‰ {end_date} ã®æœŸé–“ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤å¯¾è±¡ã¨ã—ã¾ã™")
        else:
            raise ValueError("--days ã¾ãŸã¯ --start/--end ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
        
        # å‰Šé™¤å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
        deleted_measurements = []
        total_points_deleted = 0
        
        measurements = [
            "student_progress",
            "cell_execution_metrics", 
            "performance_data",
            "help_request_events"
        ]
        
        for measurement in measurements:
            try:
                # å‰Šé™¤å¯¾è±¡ãƒ‡ãƒ¼ã‚¿æ•°ã‚’ç¢ºèª
                count_query = self._build_count_query(
                    measurement, start_time, end_time, student_email
                )
                
                count_result = self.query_api.query(count_query)
                point_count = 0
                
                for table in count_result:
                    for record in table.records:
                        if record.get_value() is not None:
                            point_count += int(record.get_value())
                
                if point_count > 0:
                    logger.info(f"ğŸ“Š {measurement}: {point_count:,} ãƒã‚¤ãƒ³ãƒˆå‰Šé™¤å¯¾è±¡")
                    
                    if not self.dry_run:
                        # å®Ÿéš›ã®å‰Šé™¤å®Ÿè¡Œ
                        predicate = self._build_delete_predicate(
                            measurement, start_time, end_time, student_email
                        )
                        
                        self.delete_api.delete(
                            start=start_time,
                            stop=end_time,
                            predicate=predicate,
                            bucket=settings.INFLUXDB_BUCKET
                        )
                        
                        logger.info(f"âœ… {measurement}: {point_count:,} ãƒã‚¤ãƒ³ãƒˆå‰Šé™¤å®Œäº†")
                    else:
                        logger.info(f"ğŸ” [DRY RUN] {measurement}: {point_count:,} ãƒã‚¤ãƒ³ãƒˆãŒå‰Šé™¤ã•ã‚Œã¾ã™")
                    
                    deleted_measurements.append({
                        "measurement": measurement,
                        "points_deleted": point_count
                    })
                    total_points_deleted += point_count
                else:
                    logger.info(f"â„¹ï¸ {measurement}: å‰Šé™¤å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãªã—")
                    
            except Exception as e:
                logger.error(f"âŒ {measurement} ã®å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ã‚µãƒãƒªãƒ¼
        result = {
            "operation": "dry_run" if self.dry_run else "delete",
            "time_range": {
                "start": start_time.isoformat(),
                "end": end_time.isoformat()
            },
            "student_filter": student_email,
            "measurements_processed": deleted_measurements,
            "total_points_deleted": total_points_deleted,
            "executed_at": datetime.utcnow().isoformat()
        }
        
        if self.dry_run:
            logger.info(f"ğŸ” [DRY RUNå®Œäº†] å‰Šé™¤å¯¾è±¡: {total_points_deleted:,} ãƒã‚¤ãƒ³ãƒˆ")
        else:
            logger.info(f"âœ… [å‰Šé™¤å®Œäº†] {total_points_deleted:,} ãƒã‚¤ãƒ³ãƒˆå‰Šé™¤")
        
        return result
    
    def _build_count_query(
        self, 
        measurement: str, 
        start_time: datetime, 
        end_time: datetime,
        student_email: Optional[str] = None
    ) -> str:
        """ã‚«ã‚¦ãƒ³ãƒˆã‚¯ã‚¨ãƒªã‚’æ§‹ç¯‰"""
        query = f'''
        from(bucket: "{settings.INFLUXDB_BUCKET}")
          |> range(start: {start_time.strftime("%Y-%m-%dT%H:%M:%SZ")}, 
                   stop: {end_time.strftime("%Y-%m-%dT%H:%M:%SZ")})
          |> filter(fn: (r) => r["_measurement"] == "{measurement}")
        '''
        
        if student_email:
            query += f'  |> filter(fn: (r) => r["emailAddress"] == "{student_email}")\n'
        
        query += '  |> count()\n'
        
        return query
    
    def _build_delete_predicate(
        self, 
        measurement: str,
        start_time: datetime,
        end_time: datetime, 
        student_email: Optional[str] = None
    ) -> str:
        """å‰Šé™¤æ¡ä»¶ã‚’æ§‹ç¯‰"""
        predicate = f'_measurement="{measurement}"'
        
        if student_email:
            predicate += f' AND emailAddress="{student_email}"'
        
        return predicate
    
    def get_storage_stats(self) -> dict:
        """ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ä½¿ç”¨é‡çµ±è¨ˆã‚’å–å¾—"""
        try:
            # ãƒã‚±ãƒƒãƒˆä½¿ç”¨é‡ã‚¯ã‚¨ãƒª
            usage_query = f'''
            from(bucket: "{settings.INFLUXDB_BUCKET}")
              |> range(start: -30d)
              |> group(columns: ["_measurement"])
              |> count()
            '''
            
            result = self.query_api.query(usage_query)
            
            usage_stats = {}
            for table in result:
                for record in table.records:
                    measurement = record.values.get("_measurement")
                    count = record.get_value()
                    if measurement and count:
                        usage_stats[measurement] = count
            
            total_points = sum(usage_stats.values())
            
            return {
                "bucket": settings.INFLUXDB_BUCKET,
                "total_points_30d": total_points,
                "measurements": usage_stats,
                "generated_at": datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            logger.error(f"ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}
    
    def close(self):
        """æ¥ç¶šã‚’é–‰ã˜ã‚‹"""
        if self.influx_client:
            self.influx_client.close()
            logger.info("InfluxDBæ¥ç¶šã‚’é–‰ã˜ã¾ã—ãŸ")


def main():
    parser = argparse.ArgumentParser(
        description="InfluxDBå¤ã„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ„ãƒ¼ãƒ«",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    
    # æ™‚é–“ç¯„å›²æŒ‡å®šï¼ˆæ–¹æ³•1: æ—¥æ•°æŒ‡å®šï¼‰
    parser.add_argument(
        "--days", 
        type=int,
        help="æŒ‡å®šã—ãŸæ—¥æ•°ä»¥ä¸Šå‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ï¼ˆä¾‹: --days 90ï¼‰"
    )
    
    # æ™‚é–“ç¯„å›²æŒ‡å®šï¼ˆæ–¹æ³•2: æœŸé–“æŒ‡å®šï¼‰
    parser.add_argument(
        "--start",
        type=str,
        help="å‰Šé™¤é–‹å§‹æ—¥æ™‚ï¼ˆISOå½¢å¼: 2025-01-01T00:00:00ï¼‰"
    )
    parser.add_argument(
        "--end", 
        type=str,
        help="å‰Šé™¤çµ‚äº†æ—¥æ™‚ï¼ˆISOå½¢å¼: 2025-02-01T00:00:00ï¼‰"
    )
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    parser.add_argument(
        "--student",
        type=str,
        help="ç‰¹å®šå­¦ç”Ÿã®ãƒ‡ãƒ¼ã‚¿ã®ã¿å‰Šé™¤ï¼ˆãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹æŒ‡å®šï¼‰"
    )
    
    # å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="å®Ÿéš›ã«ã¯å‰Šé™¤ã›ãšã€å‰Šé™¤å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã®ã¿è¡¨ç¤º"
    )
    
    # çµ±è¨ˆè¡¨ç¤º
    parser.add_argument(
        "--stats",
        action="store_true", 
        help="ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ä½¿ç”¨é‡çµ±è¨ˆã®ã¿è¡¨ç¤º"
    )
    
    args = parser.parse_args()
    
    # å¼•æ•°æ¤œè¨¼
    if not args.stats and not args.days and not (args.start and args.end):
        parser.error("--days ã¾ãŸã¯ --start/--end ã¾ãŸã¯ --stats ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
    
    if args.start and not args.end:
        parser.error("--start ã‚’æŒ‡å®šã—ãŸå ´åˆã€--end ã‚‚å¿…è¦ã§ã™")
    
    try:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œ
        cleanup = InfluxDBMetricsCleanup(dry_run=args.dry_run)
        
        if args.stats:
            # çµ±è¨ˆæƒ…å ±ã®ã¿è¡¨ç¤º
            stats = cleanup.get_storage_stats()
            print("\nğŸ“Š InfluxDB ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ä½¿ç”¨é‡çµ±è¨ˆ (éå»30æ—¥)")
            print("=" * 50)
            print(f"ãƒã‚±ãƒƒãƒˆ: {stats.get('bucket', 'N/A')}")
            print(f"ç·ãƒã‚¤ãƒ³ãƒˆæ•°: {stats.get('total_points_30d', 0):,}")
            print("\nğŸ“‹ Measurementåˆ¥ãƒã‚¤ãƒ³ãƒˆæ•°:")
            
            for measurement, count in stats.get('measurements', {}).items():
                print(f"  â€¢ {measurement}: {count:,} ãƒã‚¤ãƒ³ãƒˆ")
            
            print(f"\nç”Ÿæˆæ™‚åˆ»: {stats.get('generated_at', 'N/A')}")
        else:
            # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œ
            result = cleanup.cleanup_old_data(
                days=args.days,
                start_date=args.start,
                end_date=args.end,
                student_email=args.student
            )
            
            # çµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º
            print(f"\n{'ğŸ” [DRY RUN] ' if args.dry_run else 'âœ… '}ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—çµæœ")
            print("=" * 50)
            print(f"æ“ä½œã‚¿ã‚¤ãƒ—: {'ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³' if args.dry_run else 'å®Ÿå‰Šé™¤'}")
            print(f"æœŸé–“: {result['time_range']['start']} ï½ {result['time_range']['end']}")
            if result['student_filter']:
                print(f"å­¦ç”Ÿãƒ•ã‚£ãƒ«ã‚¿: {result['student_filter']}")
            print(f"{'å‰Šé™¤å¯¾è±¡' if args.dry_run else 'å‰Šé™¤æ¸ˆã¿'}ãƒã‚¤ãƒ³ãƒˆæ•°: {result['total_points_deleted']:,}")
            
            print("\nğŸ“‹ Measurementåˆ¥è©³ç´°:")
            for item in result['measurements_processed']:
                status = "å‰Šé™¤å¯¾è±¡" if args.dry_run else "å‰Šé™¤å®Œäº†"
                print(f"  â€¢ {item['measurement']}: {item['points_deleted']:,} ãƒã‚¤ãƒ³ãƒˆ ({status})")
        
        cleanup.close()
        
    except Exception as e:
        logger.error(f"âŒ ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()